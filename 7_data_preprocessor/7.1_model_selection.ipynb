{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "colours = sns.color_palette(\"Set2\")\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from model_tester import test_embedding_models\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "from utils import get_table_from_supabase\n",
    "\n",
    "#get keys from env\n",
    "load_dotenv()\n",
    "url = os.getenv(\"SUPABASE_URL\")\n",
    "key = os.getenv(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recipient Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until this point, the database was limited to recipient names and activities. I have chosen to extend this to include recipient objectives to hopefully enrich the data and provide another context to test for the embedding model selection. I have updated the database builders, so that objectives can be imported from the start in future iterations, and also created `2_recipients_table_builder/recipient_objectives_importer.py` so that I do not have to re-build the entire database at this point in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data from Supabase and Building Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will connect to Supabase and retrieve the relevant records, in order to isolate the text data that I will use to embed and select the best model. For this purpose, I will use the 12 funder-recipient pairs that I have curated for my evaluation app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get evaluation pairs and extract ids\n",
    "evaluation_pairs = get_table_from_supabase(url, key, \"evaluation_pairs\")\n",
    "funder_ids = evaluation_pairs[\"funder_registered_num\"].unique()\n",
    "eval_recip_ids = evaluation_pairs[\"recipient_id\"].unique()\n",
    "\n",
    "#add my ratings to compare later\n",
    "ratings = {\n",
    "    1: 0.25,\n",
    "    2: 0.60,\n",
    "    3: 0.25,\n",
    "    4: 0.25,\n",
    "    5: 0.10,\n",
    "    6: 0.60,\n",
    "    7: 0.60,\n",
    "    8: 0.25,\n",
    "    9: 0.25,\n",
    "    10: 0.25,\n",
    "    11: 0.80,\n",
    "    12: 0.30\n",
    "}\n",
    "evaluation_pairs[\"my_rating\"] = evaluation_pairs[\"id\"].map(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the 12 funders and recipients\n",
    "funders = get_table_from_supabase(url, key, \"funders\")\n",
    "funders = funders[funders[\"registered_num\"].isin(funder_ids)]\n",
    "\n",
    "recipients = get_table_from_supabase(url, key, \"recipients\")\n",
    "recipients = recipients[recipients[\"recipient_id\"].isin(eval_recip_ids)]\n",
    "\n",
    "#create dataframes\n",
    "recipients_df = recipients.copy()\n",
    "funders_df = funders.copy()\n",
    "\n",
    "#add embedding columns to funder/recipient dfs\n",
    "funders_df[\"embeddings\"] = None\n",
    "recipients_df[\"embeddings\"] = None\n",
    "\n",
    "#add funder and recipient names to pairs df\n",
    "evaluation_pairs = evaluation_pairs.merge(\n",
    "    funders_df[[\"registered_num\", \"name\"]],\n",
    "    left_on=\"funder_registered_num\",\n",
    "    right_on=\"registered_num\",\n",
    "    how=\"left\"\n",
    ")\n",
    "evaluation_pairs = evaluation_pairs.rename(columns={\"name\": \"funder_name\"})\n",
    "evaluation_pairs = evaluation_pairs.drop(columns=[\"registered_num\"])\n",
    "evaluation_pairs = evaluation_pairs.merge(\n",
    "    recipients_df[[\"recipient_id\", \"recipient_name\"]],\n",
    "    on=\"recipient_id\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check dfs\n",
    "print(f\"Recipients: {recipients_df.shape} | Funders: {funders_df.shape} | Evaluation Pairs: {evaluation_pairs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create checkpoint - save dfs to pickle\n",
    "# recipients_df.to_pickle(\"recipients_df.pkl\")\n",
    "# funders_df.to_pickle(\"funders_df.pkl\")\n",
    "# evaluation_pairs.to_pickle(\"evaluation_pairs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipients_df = pd.read_pickle(\"recipients_df.pkl\")\n",
    "funders_df = pd.read_pickle(\"funders_df.pkl\")\n",
    "evaluation_pairs = pd.read_pickle(\"evaluation_pairs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Model Evaluation by Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen to test four models on my small evaluation dataset: \n",
    "- `all-MiniLM-L6-v2`\n",
    "- `snowflake-arctic-embed-s`\n",
    "- `all-roberta-large-v1`\n",
    "- `bge-large-en-v1.5` \n",
    "\n",
    "Snowflake's model is generally finetuned for retrieval but I have decided to include it as it has performed so highly against other benchmarks and compared to major competitors (Merrick et al, 2024). The other models are consistent with the analysis by Pavlyshenko and Stasiuk (2025), who found these architectures to be reliable on semantic similarity tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add model names\n",
    "models = [\"all-MiniLM-L6-v2\", \"Snowflake/snowflake-arctic-embed-s\", \"all-roberta-large-v1\", \"BAAI/bge-large-en-v1.5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 - Activities Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare text columns\n",
    "recipients_df[\"recipients_text\"] = recipients_df[\"recipient_activities\"].fillna(\"\").str.lower()\n",
    "funders_df[\"funders_text\"] = funders_df[\"activities\"].fillna(\"\").str.lower()\n",
    "\n",
    "results_act = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2: 2.8s\n",
      "Snowflake/snowflake-arctic-embed-s: 4.2s\n",
      "all-roberta-large-v1: 16.3s\n",
      "BAAI/bge-large-en-v1.5: 18.1s\n",
      "\n",
      "Total test time: 41.4s\n"
     ]
    }
   ],
   "source": [
    "#test models\n",
    "results_act_df, pairs_act = test_embedding_models(\n",
    "    models_list=models,\n",
    "    funders_df=funders_df,\n",
    "    recipients_df=recipients_df,\n",
    "    evaluation_pairs=evaluation_pairs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.428581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snowflake/snowflake-arctic-embed-s</td>\n",
       "      <td>0.494854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all-roberta-large-v1</td>\n",
       "      <td>0.362084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAAI/bge-large-en-v1.5</td>\n",
       "      <td>0.544787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model  correlation\n",
       "0                    all-MiniLM-L6-v2     0.428581\n",
       "1  Snowflake/snowflake-arctic-embed-s     0.494854\n",
       "2                all-roberta-large-v1     0.362084\n",
       "3              BAAI/bge-large-en-v1.5     0.544787"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_act_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>funder_registered_num</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>my_rating</th>\n",
       "      <th>funder_name</th>\n",
       "      <th>recipient_name</th>\n",
       "      <th>all-MiniLM-L6-v2_sim</th>\n",
       "      <th>Snowflake/snowflake-arctic-embed-s_sim</th>\n",
       "      <th>all-roberta-large-v1_sim</th>\n",
       "      <th>BAAI/bge-large-en-v1.5_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>298633</td>\n",
       "      <td>1207372</td>\n",
       "      <td>0.25</td>\n",
       "      <td>BACON CHARITABLE TRUST</td>\n",
       "      <td>CATTON GROVE COMMUNITY CENTRE CIO</td>\n",
       "      <td>0.137608</td>\n",
       "      <td>0.665662</td>\n",
       "      <td>0.056390</td>\n",
       "      <td>0.389297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1153470</td>\n",
       "      <td>1186661</td>\n",
       "      <td>0.60</td>\n",
       "      <td>BEAVERBROOK FOUNDATION</td>\n",
       "      <td>FAITH IN LATER LIFE LTD</td>\n",
       "      <td>0.417965</td>\n",
       "      <td>0.780605</td>\n",
       "      <td>0.545531</td>\n",
       "      <td>0.617812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>219289</td>\n",
       "      <td>206002</td>\n",
       "      <td>0.25</td>\n",
       "      <td>JESSIE SPENCER TRUST</td>\n",
       "      <td>COMBAT STRESS</td>\n",
       "      <td>0.364039</td>\n",
       "      <td>0.712122</td>\n",
       "      <td>0.352171</td>\n",
       "      <td>0.439073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>287947</td>\n",
       "      <td>1205530</td>\n",
       "      <td>0.25</td>\n",
       "      <td>GRUT TRUST</td>\n",
       "      <td>NORTHERN CANCER VOICES</td>\n",
       "      <td>0.212899</td>\n",
       "      <td>0.643029</td>\n",
       "      <td>0.253448</td>\n",
       "      <td>0.500751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1190334</td>\n",
       "      <td>1146676</td>\n",
       "      <td>0.10</td>\n",
       "      <td>JOHN WHIPPY FOUNDATION</td>\n",
       "      <td>ANIMAL RESCUE CYMRU</td>\n",
       "      <td>0.243448</td>\n",
       "      <td>0.644499</td>\n",
       "      <td>0.300965</td>\n",
       "      <td>0.473758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>261685</td>\n",
       "      <td>1194238</td>\n",
       "      <td>0.60</td>\n",
       "      <td>MRS WATERHOUSE CHARITABLE TRUST</td>\n",
       "      <td>KIDZ KLUB - LEEDS</td>\n",
       "      <td>0.340170</td>\n",
       "      <td>0.649794</td>\n",
       "      <td>0.470843</td>\n",
       "      <td>0.453494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1030939</td>\n",
       "      <td>1201946</td>\n",
       "      <td>0.60</td>\n",
       "      <td>TESLER FOUNDATION</td>\n",
       "      <td>SEVENTH HEAVEN</td>\n",
       "      <td>0.359645</td>\n",
       "      <td>0.766179</td>\n",
       "      <td>0.609667</td>\n",
       "      <td>0.621728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1193351</td>\n",
       "      <td>204330</td>\n",
       "      <td>0.25</td>\n",
       "      <td>FRIENDS OF FAWLEY CHURCH</td>\n",
       "      <td>BERKSHIRE, BUCKINGHAMSHIRE AND OXFORDSHIRE WIL...</td>\n",
       "      <td>0.310445</td>\n",
       "      <td>0.691930</td>\n",
       "      <td>0.271297</td>\n",
       "      <td>0.545181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1109733</td>\n",
       "      <td>1000414</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3 TS CHARITABLE TRUST</td>\n",
       "      <td>WELDMAR HOSPICECARE</td>\n",
       "      <td>0.316463</td>\n",
       "      <td>0.752316</td>\n",
       "      <td>0.340665</td>\n",
       "      <td>0.532011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>261567</td>\n",
       "      <td>1000340</td>\n",
       "      <td>0.25</td>\n",
       "      <td>DAVID AND RUTH BEHREND FUND</td>\n",
       "      <td>FREEDOM FROM TORTURE</td>\n",
       "      <td>0.085753</td>\n",
       "      <td>0.667525</td>\n",
       "      <td>0.143934</td>\n",
       "      <td>0.472852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1190365</td>\n",
       "      <td>1162478</td>\n",
       "      <td>0.80</td>\n",
       "      <td>OSCAR MONTGOMERY ENVIRONMENTAL FOUNDATION</td>\n",
       "      <td>WILD TROUT TRUST LIMITED</td>\n",
       "      <td>0.303990</td>\n",
       "      <td>0.726473</td>\n",
       "      <td>0.143064</td>\n",
       "      <td>0.588655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>256025</td>\n",
       "      <td>1112590</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NINEVEH CHARITABLE TRUST</td>\n",
       "      <td>CANTERBURY CATHEDRAL TRUST FUND</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>0.703299</td>\n",
       "      <td>0.343136</td>\n",
       "      <td>0.585674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id funder_registered_num recipient_id  my_rating  \\\n",
       "0    1                298633      1207372       0.25   \n",
       "1    2               1153470      1186661       0.60   \n",
       "2    3                219289       206002       0.25   \n",
       "3    4                287947      1205530       0.25   \n",
       "4    5               1190334      1146676       0.10   \n",
       "5    6                261685      1194238       0.60   \n",
       "6    7               1030939      1201946       0.60   \n",
       "7    8               1193351       204330       0.25   \n",
       "8    9               1109733      1000414       0.25   \n",
       "9   10                261567      1000340       0.25   \n",
       "10  11               1190365      1162478       0.80   \n",
       "11  12                256025      1112590       0.30   \n",
       "\n",
       "                                  funder_name  \\\n",
       "0                      BACON CHARITABLE TRUST   \n",
       "1                      BEAVERBROOK FOUNDATION   \n",
       "2                        JESSIE SPENCER TRUST   \n",
       "3                                  GRUT TRUST   \n",
       "4                      JOHN WHIPPY FOUNDATION   \n",
       "5             MRS WATERHOUSE CHARITABLE TRUST   \n",
       "6                           TESLER FOUNDATION   \n",
       "7                    FRIENDS OF FAWLEY CHURCH   \n",
       "8                       3 TS CHARITABLE TRUST   \n",
       "9                 DAVID AND RUTH BEHREND FUND   \n",
       "10  OSCAR MONTGOMERY ENVIRONMENTAL FOUNDATION   \n",
       "11                   NINEVEH CHARITABLE TRUST   \n",
       "\n",
       "                                       recipient_name  all-MiniLM-L6-v2_sim  \\\n",
       "0                   CATTON GROVE COMMUNITY CENTRE CIO              0.137608   \n",
       "1                             FAITH IN LATER LIFE LTD              0.417965   \n",
       "2                                       COMBAT STRESS              0.364039   \n",
       "3                              NORTHERN CANCER VOICES              0.212899   \n",
       "4                                 ANIMAL RESCUE CYMRU              0.243448   \n",
       "5                                   KIDZ KLUB - LEEDS              0.340170   \n",
       "6                                      SEVENTH HEAVEN              0.359645   \n",
       "7   BERKSHIRE, BUCKINGHAMSHIRE AND OXFORDSHIRE WIL...              0.310445   \n",
       "8                                 WELDMAR HOSPICECARE              0.316463   \n",
       "9                                FREEDOM FROM TORTURE              0.085753   \n",
       "10                           WILD TROUT TRUST LIMITED              0.303990   \n",
       "11                    CANTERBURY CATHEDRAL TRUST FUND              0.408553   \n",
       "\n",
       "    Snowflake/snowflake-arctic-embed-s_sim  all-roberta-large-v1_sim  \\\n",
       "0                                 0.665662                  0.056390   \n",
       "1                                 0.780605                  0.545531   \n",
       "2                                 0.712122                  0.352171   \n",
       "3                                 0.643029                  0.253448   \n",
       "4                                 0.644499                  0.300965   \n",
       "5                                 0.649794                  0.470843   \n",
       "6                                 0.766179                  0.609667   \n",
       "7                                 0.691930                  0.271297   \n",
       "8                                 0.752316                  0.340665   \n",
       "9                                 0.667525                  0.143934   \n",
       "10                                0.726473                  0.143064   \n",
       "11                                0.703299                  0.343136   \n",
       "\n",
       "    BAAI/bge-large-en-v1.5_sim  \n",
       "0                     0.389297  \n",
       "1                     0.617812  \n",
       "2                     0.439073  \n",
       "3                     0.500751  \n",
       "4                     0.473758  \n",
       "5                     0.453494  \n",
       "6                     0.621728  \n",
       "7                     0.545181  \n",
       "8                     0.532011  \n",
       "9                     0.472852  \n",
       "10                    0.588655  \n",
       "11                    0.585674  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view pairs with scores from each model\n",
    "pairs_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2 - Objectives Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare text columns\n",
    "recipients_df[\"recipients_text\"] = recipients_df[\"recipient_objectives\"].fillna(\"\").str.lower()\n",
    "funders_df[\"funders_text\"] = funders_df[\"objectives\"].fillna(\"\").str.lower()\n",
    "\n",
    "results_obj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2: 4.2s\n",
      "Snowflake/snowflake-arctic-embed-s: 16.2s\n",
      "all-roberta-large-v1: 85.3s\n",
      "BAAI/bge-large-en-v1.5: 1463.5s\n",
      "\n",
      "Total test time: 1569.1s\n"
     ]
    }
   ],
   "source": [
    "#test models\n",
    "results_obj_df, pairs_obj = test_embedding_models(\n",
    "    models_list=models,\n",
    "    funders_df=funders_df,\n",
    "    recipients_df=recipients_df,\n",
    "    evaluation_pairs=evaluation_pairs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.390847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snowflake/snowflake-arctic-embed-s</td>\n",
       "      <td>0.155233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all-roberta-large-v1</td>\n",
       "      <td>0.040845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAAI/bge-large-en-v1.5</td>\n",
       "      <td>0.413909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model  correlation\n",
       "0                    all-MiniLM-L6-v2     0.390847\n",
       "1  Snowflake/snowflake-arctic-embed-s     0.155233\n",
       "2                all-roberta-large-v1     0.040845\n",
       "3              BAAI/bge-large-en-v1.5     0.413909"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_obj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>funder_registered_num</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>my_rating</th>\n",
       "      <th>funder_name</th>\n",
       "      <th>recipient_name</th>\n",
       "      <th>all-MiniLM-L6-v2_sim</th>\n",
       "      <th>Snowflake/snowflake-arctic-embed-s_sim</th>\n",
       "      <th>all-roberta-large-v1_sim</th>\n",
       "      <th>BAAI/bge-large-en-v1.5_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>298633</td>\n",
       "      <td>1207372</td>\n",
       "      <td>0.25</td>\n",
       "      <td>BACON CHARITABLE TRUST</td>\n",
       "      <td>CATTON GROVE COMMUNITY CENTRE CIO</td>\n",
       "      <td>0.453526</td>\n",
       "      <td>0.781387</td>\n",
       "      <td>0.513125</td>\n",
       "      <td>0.581706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1153470</td>\n",
       "      <td>1186661</td>\n",
       "      <td>0.60</td>\n",
       "      <td>BEAVERBROOK FOUNDATION</td>\n",
       "      <td>FAITH IN LATER LIFE LTD</td>\n",
       "      <td>0.449202</td>\n",
       "      <td>0.757412</td>\n",
       "      <td>0.443285</td>\n",
       "      <td>0.600509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>219289</td>\n",
       "      <td>206002</td>\n",
       "      <td>0.25</td>\n",
       "      <td>JESSIE SPENCER TRUST</td>\n",
       "      <td>COMBAT STRESS</td>\n",
       "      <td>0.268072</td>\n",
       "      <td>0.724604</td>\n",
       "      <td>0.457703</td>\n",
       "      <td>0.577598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>287947</td>\n",
       "      <td>1205530</td>\n",
       "      <td>0.25</td>\n",
       "      <td>GRUT TRUST</td>\n",
       "      <td>NORTHERN CANCER VOICES</td>\n",
       "      <td>0.230132</td>\n",
       "      <td>0.738383</td>\n",
       "      <td>0.422057</td>\n",
       "      <td>0.530364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1190334</td>\n",
       "      <td>1146676</td>\n",
       "      <td>0.10</td>\n",
       "      <td>JOHN WHIPPY FOUNDATION</td>\n",
       "      <td>ANIMAL RESCUE CYMRU</td>\n",
       "      <td>0.428428</td>\n",
       "      <td>0.772618</td>\n",
       "      <td>0.499018</td>\n",
       "      <td>0.630147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>261685</td>\n",
       "      <td>1194238</td>\n",
       "      <td>0.60</td>\n",
       "      <td>MRS WATERHOUSE CHARITABLE TRUST</td>\n",
       "      <td>KIDZ KLUB - LEEDS</td>\n",
       "      <td>0.381480</td>\n",
       "      <td>0.687084</td>\n",
       "      <td>0.404759</td>\n",
       "      <td>0.563782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1030939</td>\n",
       "      <td>1201946</td>\n",
       "      <td>0.60</td>\n",
       "      <td>TESLER FOUNDATION</td>\n",
       "      <td>SEVENTH HEAVEN</td>\n",
       "      <td>0.407416</td>\n",
       "      <td>0.801899</td>\n",
       "      <td>0.428882</td>\n",
       "      <td>0.564134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1193351</td>\n",
       "      <td>204330</td>\n",
       "      <td>0.25</td>\n",
       "      <td>FRIENDS OF FAWLEY CHURCH</td>\n",
       "      <td>BERKSHIRE, BUCKINGHAMSHIRE AND OXFORDSHIRE WIL...</td>\n",
       "      <td>0.269549</td>\n",
       "      <td>0.709543</td>\n",
       "      <td>0.388170</td>\n",
       "      <td>0.570597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1109733</td>\n",
       "      <td>1000414</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3 TS CHARITABLE TRUST</td>\n",
       "      <td>WELDMAR HOSPICECARE</td>\n",
       "      <td>0.301665</td>\n",
       "      <td>0.789241</td>\n",
       "      <td>0.408023</td>\n",
       "      <td>0.593135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>261567</td>\n",
       "      <td>1000340</td>\n",
       "      <td>0.25</td>\n",
       "      <td>DAVID AND RUTH BEHREND FUND</td>\n",
       "      <td>FREEDOM FROM TORTURE</td>\n",
       "      <td>-0.018109</td>\n",
       "      <td>0.621459</td>\n",
       "      <td>0.118740</td>\n",
       "      <td>0.461444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1190365</td>\n",
       "      <td>1162478</td>\n",
       "      <td>0.80</td>\n",
       "      <td>OSCAR MONTGOMERY ENVIRONMENTAL FOUNDATION</td>\n",
       "      <td>WILD TROUT TRUST LIMITED</td>\n",
       "      <td>0.414099</td>\n",
       "      <td>0.783237</td>\n",
       "      <td>0.440046</td>\n",
       "      <td>0.721016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>256025</td>\n",
       "      <td>1112590</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NINEVEH CHARITABLE TRUST</td>\n",
       "      <td>CANTERBURY CATHEDRAL TRUST FUND</td>\n",
       "      <td>0.344772</td>\n",
       "      <td>0.803915</td>\n",
       "      <td>0.514731</td>\n",
       "      <td>0.628567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id funder_registered_num recipient_id  my_rating  \\\n",
       "0    1                298633      1207372       0.25   \n",
       "1    2               1153470      1186661       0.60   \n",
       "2    3                219289       206002       0.25   \n",
       "3    4                287947      1205530       0.25   \n",
       "4    5               1190334      1146676       0.10   \n",
       "5    6                261685      1194238       0.60   \n",
       "6    7               1030939      1201946       0.60   \n",
       "7    8               1193351       204330       0.25   \n",
       "8    9               1109733      1000414       0.25   \n",
       "9   10                261567      1000340       0.25   \n",
       "10  11               1190365      1162478       0.80   \n",
       "11  12                256025      1112590       0.30   \n",
       "\n",
       "                                  funder_name  \\\n",
       "0                      BACON CHARITABLE TRUST   \n",
       "1                      BEAVERBROOK FOUNDATION   \n",
       "2                        JESSIE SPENCER TRUST   \n",
       "3                                  GRUT TRUST   \n",
       "4                      JOHN WHIPPY FOUNDATION   \n",
       "5             MRS WATERHOUSE CHARITABLE TRUST   \n",
       "6                           TESLER FOUNDATION   \n",
       "7                    FRIENDS OF FAWLEY CHURCH   \n",
       "8                       3 TS CHARITABLE TRUST   \n",
       "9                 DAVID AND RUTH BEHREND FUND   \n",
       "10  OSCAR MONTGOMERY ENVIRONMENTAL FOUNDATION   \n",
       "11                   NINEVEH CHARITABLE TRUST   \n",
       "\n",
       "                                       recipient_name  all-MiniLM-L6-v2_sim  \\\n",
       "0                   CATTON GROVE COMMUNITY CENTRE CIO              0.453526   \n",
       "1                             FAITH IN LATER LIFE LTD              0.449202   \n",
       "2                                       COMBAT STRESS              0.268072   \n",
       "3                              NORTHERN CANCER VOICES              0.230132   \n",
       "4                                 ANIMAL RESCUE CYMRU              0.428428   \n",
       "5                                   KIDZ KLUB - LEEDS              0.381480   \n",
       "6                                      SEVENTH HEAVEN              0.407416   \n",
       "7   BERKSHIRE, BUCKINGHAMSHIRE AND OXFORDSHIRE WIL...              0.269549   \n",
       "8                                 WELDMAR HOSPICECARE              0.301665   \n",
       "9                                FREEDOM FROM TORTURE             -0.018109   \n",
       "10                           WILD TROUT TRUST LIMITED              0.414099   \n",
       "11                    CANTERBURY CATHEDRAL TRUST FUND              0.344772   \n",
       "\n",
       "    Snowflake/snowflake-arctic-embed-s_sim  all-roberta-large-v1_sim  \\\n",
       "0                                 0.781387                  0.513125   \n",
       "1                                 0.757412                  0.443285   \n",
       "2                                 0.724604                  0.457703   \n",
       "3                                 0.738383                  0.422057   \n",
       "4                                 0.772618                  0.499018   \n",
       "5                                 0.687084                  0.404759   \n",
       "6                                 0.801899                  0.428882   \n",
       "7                                 0.709543                  0.388170   \n",
       "8                                 0.789241                  0.408023   \n",
       "9                                 0.621459                  0.118740   \n",
       "10                                0.783237                  0.440046   \n",
       "11                                0.803915                  0.514731   \n",
       "\n",
       "    BAAI/bge-large-en-v1.5_sim  \n",
       "0                     0.581706  \n",
       "1                     0.600509  \n",
       "2                     0.577598  \n",
       "3                     0.530364  \n",
       "4                     0.630147  \n",
       "5                     0.563782  \n",
       "6                     0.564134  \n",
       "7                     0.570597  \n",
       "8                     0.593135  \n",
       "9                     0.461444  \n",
       "10                    0.721016  \n",
       "11                    0.628567  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3 - Activities and Objectives (API Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reject bge-large-en-v1.5\n",
    "models = [\"all-MiniLM-L6-v2\", \"Snowflake/snowflake-arctic-embed-s\", \"all-roberta-large-v1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare text columns\n",
    "recipients_df[\"recipients_text\"] = recipients_df[\"recipient_activities\"].fillna(\"\") + \"\" + recipients_df[\"recipient_objectives\"].fillna(\"\").str.lower()\n",
    "funders_df[\"funders_text\"] = funders_df[\"activities\"].fillna(\"\") + \"\" + funders_df[\"objectives\"].fillna(\"\").str.lower()\n",
    "\n",
    "results_ao_api = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2: 4.5s\n",
      "Snowflake/snowflake-arctic-embed-s: 44.2s\n",
      "all-roberta-large-v1: 68.4s\n",
      "\n",
      "Total test time: 117.1s\n"
     ]
    }
   ],
   "source": [
    "#test models\n",
    "results_ao_api, pairs_ao_api = test_embedding_models(\n",
    "    models_list=models,\n",
    "    funders_df=funders_df,\n",
    "    recipients_df=recipients_df,\n",
    "    evaluation_pairs=evaluation_pairs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.358693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snowflake/snowflake-arctic-embed-s</td>\n",
       "      <td>0.221325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all-roberta-large-v1</td>\n",
       "      <td>0.439121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model  correlation\n",
       "0                    all-MiniLM-L6-v2     0.358693\n",
       "1  Snowflake/snowflake-arctic-embed-s     0.221325\n",
       "2                all-roberta-large-v1     0.439121"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ao_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>funder_registered_num</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>my_rating</th>\n",
       "      <th>funder_name</th>\n",
       "      <th>recipient_name</th>\n",
       "      <th>all-MiniLM-L6-v2_sim</th>\n",
       "      <th>Snowflake/snowflake-arctic-embed-s_sim</th>\n",
       "      <th>all-roberta-large-v1_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>298633</td>\n",
       "      <td>1207372</td>\n",
       "      <td>0.25</td>\n",
       "      <td>BACON CHARITABLE TRUST</td>\n",
       "      <td>CATTON GROVE COMMUNITY CENTRE CIO</td>\n",
       "      <td>0.329249</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>0.402899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1153470</td>\n",
       "      <td>1186661</td>\n",
       "      <td>0.60</td>\n",
       "      <td>BEAVERBROOK FOUNDATION</td>\n",
       "      <td>FAITH IN LATER LIFE LTD</td>\n",
       "      <td>0.373479</td>\n",
       "      <td>0.732705</td>\n",
       "      <td>0.668525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>219289</td>\n",
       "      <td>206002</td>\n",
       "      <td>0.25</td>\n",
       "      <td>JESSIE SPENCER TRUST</td>\n",
       "      <td>COMBAT STRESS</td>\n",
       "      <td>0.352096</td>\n",
       "      <td>0.696573</td>\n",
       "      <td>0.307511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>287947</td>\n",
       "      <td>1205530</td>\n",
       "      <td>0.25</td>\n",
       "      <td>GRUT TRUST</td>\n",
       "      <td>NORTHERN CANCER VOICES</td>\n",
       "      <td>0.273982</td>\n",
       "      <td>0.608131</td>\n",
       "      <td>0.332433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1190334</td>\n",
       "      <td>1146676</td>\n",
       "      <td>0.10</td>\n",
       "      <td>JOHN WHIPPY FOUNDATION</td>\n",
       "      <td>ANIMAL RESCUE CYMRU</td>\n",
       "      <td>0.442093</td>\n",
       "      <td>0.719338</td>\n",
       "      <td>0.499278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>261685</td>\n",
       "      <td>1194238</td>\n",
       "      <td>0.60</td>\n",
       "      <td>MRS WATERHOUSE CHARITABLE TRUST</td>\n",
       "      <td>KIDZ KLUB - LEEDS</td>\n",
       "      <td>0.299915</td>\n",
       "      <td>0.636555</td>\n",
       "      <td>0.446879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1030939</td>\n",
       "      <td>1201946</td>\n",
       "      <td>0.60</td>\n",
       "      <td>TESLER FOUNDATION</td>\n",
       "      <td>SEVENTH HEAVEN</td>\n",
       "      <td>0.404599</td>\n",
       "      <td>0.737443</td>\n",
       "      <td>0.557278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1193351</td>\n",
       "      <td>204330</td>\n",
       "      <td>0.25</td>\n",
       "      <td>FRIENDS OF FAWLEY CHURCH</td>\n",
       "      <td>BERKSHIRE, BUCKINGHAMSHIRE AND OXFORDSHIRE WIL...</td>\n",
       "      <td>0.277628</td>\n",
       "      <td>0.684623</td>\n",
       "      <td>0.381304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1109733</td>\n",
       "      <td>1000414</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3 TS CHARITABLE TRUST</td>\n",
       "      <td>WELDMAR HOSPICECARE</td>\n",
       "      <td>0.297411</td>\n",
       "      <td>0.756840</td>\n",
       "      <td>0.424237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>261567</td>\n",
       "      <td>1000340</td>\n",
       "      <td>0.25</td>\n",
       "      <td>DAVID AND RUTH BEHREND FUND</td>\n",
       "      <td>FREEDOM FROM TORTURE</td>\n",
       "      <td>0.020152</td>\n",
       "      <td>0.654719</td>\n",
       "      <td>0.196893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1190365</td>\n",
       "      <td>1162478</td>\n",
       "      <td>0.80</td>\n",
       "      <td>OSCAR MONTGOMERY ENVIRONMENTAL FOUNDATION</td>\n",
       "      <td>WILD TROUT TRUST LIMITED</td>\n",
       "      <td>0.461748</td>\n",
       "      <td>0.740526</td>\n",
       "      <td>0.419277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>256025</td>\n",
       "      <td>1112590</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NINEVEH CHARITABLE TRUST</td>\n",
       "      <td>CANTERBURY CATHEDRAL TRUST FUND</td>\n",
       "      <td>0.360289</td>\n",
       "      <td>0.711741</td>\n",
       "      <td>0.475019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id funder_registered_num recipient_id  my_rating  \\\n",
       "0    1                298633      1207372       0.25   \n",
       "1    2               1153470      1186661       0.60   \n",
       "2    3                219289       206002       0.25   \n",
       "3    4                287947      1205530       0.25   \n",
       "4    5               1190334      1146676       0.10   \n",
       "5    6                261685      1194238       0.60   \n",
       "6    7               1030939      1201946       0.60   \n",
       "7    8               1193351       204330       0.25   \n",
       "8    9               1109733      1000414       0.25   \n",
       "9   10                261567      1000340       0.25   \n",
       "10  11               1190365      1162478       0.80   \n",
       "11  12                256025      1112590       0.30   \n",
       "\n",
       "                                  funder_name  \\\n",
       "0                      BACON CHARITABLE TRUST   \n",
       "1                      BEAVERBROOK FOUNDATION   \n",
       "2                        JESSIE SPENCER TRUST   \n",
       "3                                  GRUT TRUST   \n",
       "4                      JOHN WHIPPY FOUNDATION   \n",
       "5             MRS WATERHOUSE CHARITABLE TRUST   \n",
       "6                           TESLER FOUNDATION   \n",
       "7                    FRIENDS OF FAWLEY CHURCH   \n",
       "8                       3 TS CHARITABLE TRUST   \n",
       "9                 DAVID AND RUTH BEHREND FUND   \n",
       "10  OSCAR MONTGOMERY ENVIRONMENTAL FOUNDATION   \n",
       "11                   NINEVEH CHARITABLE TRUST   \n",
       "\n",
       "                                       recipient_name  all-MiniLM-L6-v2_sim  \\\n",
       "0                   CATTON GROVE COMMUNITY CENTRE CIO              0.329249   \n",
       "1                             FAITH IN LATER LIFE LTD              0.373479   \n",
       "2                                       COMBAT STRESS              0.352096   \n",
       "3                              NORTHERN CANCER VOICES              0.273982   \n",
       "4                                 ANIMAL RESCUE CYMRU              0.442093   \n",
       "5                                   KIDZ KLUB - LEEDS              0.299915   \n",
       "6                                      SEVENTH HEAVEN              0.404599   \n",
       "7   BERKSHIRE, BUCKINGHAMSHIRE AND OXFORDSHIRE WIL...              0.277628   \n",
       "8                                 WELDMAR HOSPICECARE              0.297411   \n",
       "9                                FREEDOM FROM TORTURE              0.020152   \n",
       "10                           WILD TROUT TRUST LIMITED              0.461748   \n",
       "11                    CANTERBURY CATHEDRAL TRUST FUND              0.360289   \n",
       "\n",
       "    Snowflake/snowflake-arctic-embed-s_sim  all-roberta-large-v1_sim  \n",
       "0                                 0.709352                  0.402899  \n",
       "1                                 0.732705                  0.668525  \n",
       "2                                 0.696573                  0.307511  \n",
       "3                                 0.608131                  0.332433  \n",
       "4                                 0.719338                  0.499278  \n",
       "5                                 0.636555                  0.446879  \n",
       "6                                 0.737443                  0.557278  \n",
       "7                                 0.684623                  0.381304  \n",
       "8                                 0.756840                  0.424237  \n",
       "9                                 0.654719                  0.196893  \n",
       "10                                0.740526                  0.419277  \n",
       "11                                0.711741                  0.475019  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_ao_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4 - Activities and Objectives (Extracted and API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare text columns\n",
    "recipients_df[\"recipients_text\"] = recipients_df[\"recipient_activities\"].fillna(\"\") + \"\" + recipients_df[\"recipient_objectives\"].fillna(\"\").str.lower()\n",
    "funders_df[\"funders_text\"] = funders_df[\"activities\"].fillna(\"\") + \"\" + funders_df[\"objectives\"].fillna(\"\") + \"\" + funders_df[\"objectives_activities\"].fillna(\"\").str.lower()\n",
    "\n",
    "results_ao_ext = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2: 4.3s\n",
      "Snowflake/snowflake-arctic-embed-s: 30.6s\n",
      "all-roberta-large-v1: 77.3s\n",
      "\n",
      "Total test time: 112.1s\n"
     ]
    }
   ],
   "source": [
    "#test models\n",
    "results_ao_ext, pairs_ao_ext = test_embedding_models(\n",
    "    models_list=models,\n",
    "    funders_df=funders_df,\n",
    "    recipients_df=recipients_df,\n",
    "    evaluation_pairs=evaluation_pairs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "      <td>0.317654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snowflake/snowflake-arctic-embed-s</td>\n",
       "      <td>0.194293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all-roberta-large-v1</td>\n",
       "      <td>0.482080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model  correlation\n",
       "0                    all-MiniLM-L6-v2     0.317654\n",
       "1  Snowflake/snowflake-arctic-embed-s     0.194293\n",
       "2                all-roberta-large-v1     0.482080"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ao_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>funder_registered_num</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>my_rating</th>\n",
       "      <th>funder_name</th>\n",
       "      <th>recipient_name</th>\n",
       "      <th>all-MiniLM-L6-v2_sim</th>\n",
       "      <th>Snowflake/snowflake-arctic-embed-s_sim</th>\n",
       "      <th>all-roberta-large-v1_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>298633</td>\n",
       "      <td>1207372</td>\n",
       "      <td>0.25</td>\n",
       "      <td>BACON CHARITABLE TRUST</td>\n",
       "      <td>CATTON GROVE COMMUNITY CENTRE CIO</td>\n",
       "      <td>0.329249</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>0.399218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1153470</td>\n",
       "      <td>1186661</td>\n",
       "      <td>0.60</td>\n",
       "      <td>BEAVERBROOK FOUNDATION</td>\n",
       "      <td>FAITH IN LATER LIFE LTD</td>\n",
       "      <td>0.373479</td>\n",
       "      <td>0.732705</td>\n",
       "      <td>0.714230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>219289</td>\n",
       "      <td>206002</td>\n",
       "      <td>0.25</td>\n",
       "      <td>JESSIE SPENCER TRUST</td>\n",
       "      <td>COMBAT STRESS</td>\n",
       "      <td>0.351395</td>\n",
       "      <td>0.667134</td>\n",
       "      <td>0.309124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>287947</td>\n",
       "      <td>1205530</td>\n",
       "      <td>0.25</td>\n",
       "      <td>GRUT TRUST</td>\n",
       "      <td>NORTHERN CANCER VOICES</td>\n",
       "      <td>0.273982</td>\n",
       "      <td>0.608131</td>\n",
       "      <td>0.336527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1190334</td>\n",
       "      <td>1146676</td>\n",
       "      <td>0.10</td>\n",
       "      <td>JOHN WHIPPY FOUNDATION</td>\n",
       "      <td>ANIMAL RESCUE CYMRU</td>\n",
       "      <td>0.442093</td>\n",
       "      <td>0.719338</td>\n",
       "      <td>0.527307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>261685</td>\n",
       "      <td>1194238</td>\n",
       "      <td>0.60</td>\n",
       "      <td>MRS WATERHOUSE CHARITABLE TRUST</td>\n",
       "      <td>KIDZ KLUB - LEEDS</td>\n",
       "      <td>0.292382</td>\n",
       "      <td>0.631720</td>\n",
       "      <td>0.513736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1030939</td>\n",
       "      <td>1201946</td>\n",
       "      <td>0.60</td>\n",
       "      <td>TESLER FOUNDATION</td>\n",
       "      <td>SEVENTH HEAVEN</td>\n",
       "      <td>0.431671</td>\n",
       "      <td>0.714170</td>\n",
       "      <td>0.509098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1193351</td>\n",
       "      <td>204330</td>\n",
       "      <td>0.25</td>\n",
       "      <td>FRIENDS OF FAWLEY CHURCH</td>\n",
       "      <td>BERKSHIRE, BUCKINGHAMSHIRE AND OXFORDSHIRE WIL...</td>\n",
       "      <td>0.277628</td>\n",
       "      <td>0.684623</td>\n",
       "      <td>0.372341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1109733</td>\n",
       "      <td>1000414</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3 TS CHARITABLE TRUST</td>\n",
       "      <td>WELDMAR HOSPICECARE</td>\n",
       "      <td>0.297411</td>\n",
       "      <td>0.756840</td>\n",
       "      <td>0.393115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>261567</td>\n",
       "      <td>1000340</td>\n",
       "      <td>0.25</td>\n",
       "      <td>DAVID AND RUTH BEHREND FUND</td>\n",
       "      <td>FREEDOM FROM TORTURE</td>\n",
       "      <td>0.050731</td>\n",
       "      <td>0.651542</td>\n",
       "      <td>0.269401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1190365</td>\n",
       "      <td>1162478</td>\n",
       "      <td>0.80</td>\n",
       "      <td>OSCAR MONTGOMERY ENVIRONMENTAL FOUNDATION</td>\n",
       "      <td>WILD TROUT TRUST LIMITED</td>\n",
       "      <td>0.461748</td>\n",
       "      <td>0.740526</td>\n",
       "      <td>0.428460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>256025</td>\n",
       "      <td>1112590</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NINEVEH CHARITABLE TRUST</td>\n",
       "      <td>CANTERBURY CATHEDRAL TRUST FUND</td>\n",
       "      <td>0.481557</td>\n",
       "      <td>0.716894</td>\n",
       "      <td>0.417061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id funder_registered_num recipient_id  my_rating  \\\n",
       "0    1                298633      1207372       0.25   \n",
       "1    2               1153470      1186661       0.60   \n",
       "2    3                219289       206002       0.25   \n",
       "3    4                287947      1205530       0.25   \n",
       "4    5               1190334      1146676       0.10   \n",
       "5    6                261685      1194238       0.60   \n",
       "6    7               1030939      1201946       0.60   \n",
       "7    8               1193351       204330       0.25   \n",
       "8    9               1109733      1000414       0.25   \n",
       "9   10                261567      1000340       0.25   \n",
       "10  11               1190365      1162478       0.80   \n",
       "11  12                256025      1112590       0.30   \n",
       "\n",
       "                                  funder_name  \\\n",
       "0                      BACON CHARITABLE TRUST   \n",
       "1                      BEAVERBROOK FOUNDATION   \n",
       "2                        JESSIE SPENCER TRUST   \n",
       "3                                  GRUT TRUST   \n",
       "4                      JOHN WHIPPY FOUNDATION   \n",
       "5             MRS WATERHOUSE CHARITABLE TRUST   \n",
       "6                           TESLER FOUNDATION   \n",
       "7                    FRIENDS OF FAWLEY CHURCH   \n",
       "8                       3 TS CHARITABLE TRUST   \n",
       "9                 DAVID AND RUTH BEHREND FUND   \n",
       "10  OSCAR MONTGOMERY ENVIRONMENTAL FOUNDATION   \n",
       "11                   NINEVEH CHARITABLE TRUST   \n",
       "\n",
       "                                       recipient_name  all-MiniLM-L6-v2_sim  \\\n",
       "0                   CATTON GROVE COMMUNITY CENTRE CIO              0.329249   \n",
       "1                             FAITH IN LATER LIFE LTD              0.373479   \n",
       "2                                       COMBAT STRESS              0.351395   \n",
       "3                              NORTHERN CANCER VOICES              0.273982   \n",
       "4                                 ANIMAL RESCUE CYMRU              0.442093   \n",
       "5                                   KIDZ KLUB - LEEDS              0.292382   \n",
       "6                                      SEVENTH HEAVEN              0.431671   \n",
       "7   BERKSHIRE, BUCKINGHAMSHIRE AND OXFORDSHIRE WIL...              0.277628   \n",
       "8                                 WELDMAR HOSPICECARE              0.297411   \n",
       "9                                FREEDOM FROM TORTURE              0.050731   \n",
       "10                           WILD TROUT TRUST LIMITED              0.461748   \n",
       "11                    CANTERBURY CATHEDRAL TRUST FUND              0.481557   \n",
       "\n",
       "    Snowflake/snowflake-arctic-embed-s_sim  all-roberta-large-v1_sim  \n",
       "0                                 0.709352                  0.399218  \n",
       "1                                 0.732705                  0.714230  \n",
       "2                                 0.667134                  0.309124  \n",
       "3                                 0.608131                  0.336527  \n",
       "4                                 0.719338                  0.527307  \n",
       "5                                 0.631720                  0.513736  \n",
       "6                                 0.714170                  0.509098  \n",
       "7                                 0.684623                  0.372341  \n",
       "8                                 0.756840                  0.393115  \n",
       "9                                 0.651542                  0.269401  \n",
       "10                                0.740526                  0.428460  \n",
       "11                                0.716894                  0.417061  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_ao_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'all-MiniLM-L6-v2_sim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/prospie/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'all-MiniLM-L6-v2_sim'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb Cell 42\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m axes \u001b[39m=\u001b[39m axes\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m idx, (model_col, title) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m([\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mall-MiniLM-L6-v2_sim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mMiniLM\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mSnowflake/snowflake-arctic-embed-s_sim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mSnowflake Arctic Embed\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mall-roberta-large-v1_sim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRoberta\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mBAAI/bge-large-en-v1.5_sim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBGE-M3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m ]):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     axes[idx]\u001b[39m.\u001b[39mscatter(evaluation_pairs[\u001b[39m\"\u001b[39m\u001b[39mmy_rating\u001b[39m\u001b[39m\"\u001b[39m], evaluation_pairs[model_col],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                         alpha\u001b[39m=\u001b[39m\u001b[39m0.6\u001b[39m, s\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, color\u001b[39m=\u001b[39mcolours[idx])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m#show line of best fit\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/liamcottrell/codingStuff/prospie-prototype/7_data_preprocessor/7.1_model_selection.ipynb#X40sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpolyfit(evaluation_pairs[\u001b[39m\"\u001b[39m\u001b[39mmy_rating\u001b[39m\u001b[39m\"\u001b[39m], evaluation_pairs[model_col], \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/prospie/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/prospie/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m\u001b[39m \u001b[39m\u001b[39merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'all-MiniLM-L6-v2_sim'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make scatterplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (model_col, title) in enumerate([\n",
    "    (\"all-MiniLM-L6-v2_sim\", \"MiniLM\"),\n",
    "    (\"Snowflake/snowflake-arctic-embed-s_sim\", \"Snowflake Arctic Embed\"),\n",
    "    (\"all-roberta-large-v1_sim\", \"Roberta\"),\n",
    "    (\"BAAI/bge-large-en-v1.5_sim\", \"BGE-M3\")\n",
    "]):\n",
    "    axes[idx].scatter(evaluation_pairs[\"my_rating\"], evaluation_pairs[model_col],\n",
    "                        alpha=0.6, s=100, color=colours[idx])\n",
    "\n",
    "    #show line of best fit\n",
    "    z = np.polyfit(evaluation_pairs[\"my_rating\"], evaluation_pairs[model_col], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[idx].plot(evaluation_pairs[\"my_rating\"].sort_values(),\n",
    "                    p(evaluation_pairs[\"my_rating\"].sort_values()),\n",
    "                    \"r-\", alpha=0.5, linewidth=2)\n",
    "\n",
    "    axes[idx].set_xlabel(\"My Rating\")\n",
    "    axes[idx].set_ylabel(\"Model Similarity Score\")\n",
    "    axes[idx].set_title(f\"{title}\\nCorrelation: {results_df.iloc[idx]['correlation']:.3f}\")\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

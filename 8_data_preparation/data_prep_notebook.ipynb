{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "colours = sns.color_palette(\"Set2\")\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "from utils import get_table_from_supabase\n",
    "\n",
    "#get keys from env\n",
    "load_dotenv()\n",
    "url = os.getenv(\"SUPABASE_URL\")\n",
    "key = os.getenv(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data from Supabase and Building Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tables and build dataframes\n",
    "funders_df = get_table_from_supabase(url, key, \"funders\")\n",
    "grants_df = get_table_from_supabase(url, key, \"grants\")\n",
    "\n",
    "#get recipients with filter\n",
    "recipients_df = get_table_from_supabase(url, key, \"recipients\", batch_size=50, filter_recipients=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoint folder\n",
    "checkpoint_folder = Path(\"./8.1_checkpoints/\")\n",
    "\n",
    "#create checkpoint - save dfs to pickle\n",
    "# recipients_df.to_pickle(checkpoint_folder / \"recipients_df.pkl\")\n",
    "# funders_df.to_pickle(checkpoint_folder / \"funders_df.pkl\")\n",
    "# grants_df.to_pickle(checkpoint_folder / \"grants_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retreiving Data from Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoint folder\n",
    "checkpoint_folder = Path(\"./8.1_checkpoints/\")\n",
    "\n",
    "# recipients_df = pd.read_pickle(checkpoint_folder / \"recipients_df.pkl\")\n",
    "# funders_df = pd.read_pickle(checkpoint_folder / \"funders_df.pkl\")\n",
    "# grants_df = pd.read_pickle(checkpoint_folder / \"grants_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Creation - Single Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create embeddings for the relevant columns. I have chosen to run each dataframe one at a time to separate these time- and compute-heavy processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-roberta-large-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name embedded successfully (996, 1024)\n",
      "activities embedded successfully (996, 1024)\n",
      "objectives embedded successfully (996, 1024)\n",
      "objectives_activities embedded successfully (996, 1024)\n",
      "achievements_performance embedded successfully (996, 1024)\n",
      "grant_policy embedded successfully (996, 1024)\n",
      "All embeddings created for funders_df!\n",
      "Total time: 138.14s\n"
     ]
    }
   ],
   "source": [
    "funders_cols = [\"name\", \"activities\", \"objectives\", \"objectives_activities\", \"achievements_performance\", \"grant_policy\"]\n",
    "\n",
    "#create embeddings\n",
    "start_time = time.time()\n",
    "for col in funders_cols:\n",
    "    #replace nans with empty string\n",
    "    texts = funders_df[col].fillna(\"\").tolist()\n",
    "    embeddings = model.encode(texts)\n",
    "    \n",
    "    #add to df\n",
    "    funders_df[f\"{col}_em\"] = list(embeddings)\n",
    "    \n",
    "    print(f\"{col} embedded successfully {embeddings.shape}\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"All embeddings created for funders_df!\")\n",
    "print(f\"Total time: {elapsed_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipient_name embedded successfully (17169, 1024)\n",
      "recipient_activities embedded successfully (17169, 1024)\n",
      "recipient_objectives embedded successfully (17169, 1024)\n",
      "All embeddings created for recipients_df!\n",
      "Total time: 952.63s\n"
     ]
    }
   ],
   "source": [
    "recipients_cols = [\"recipient_name\", \"recipient_activities\", \"recipient_objectives\"]\n",
    "\n",
    "#create embeddings\n",
    "start_time = time.time()\n",
    "for col in recipients_cols:\n",
    "    #replace nans with empty string\n",
    "    texts = recipients_df[col].fillna(\"\").tolist()\n",
    "    embeddings = model.encode(texts)\n",
    "    \n",
    "    #add to df\n",
    "    recipients_df[f\"{col}_em\"] = list(embeddings)\n",
    "    \n",
    "    print(f\"{col} embedded successfully {embeddings.shape}\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"All embeddings created for recipients_df!\")\n",
    "print(f\"Total time: {elapsed_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grant_title embedded successfully (32816, 1024)\n",
      "grant_desc embedded successfully (32816, 1024)\n",
      "All embeddings created for grants_df!\n",
      "Total time: 759.85s\n"
     ]
    }
   ],
   "source": [
    "grants_cols = [\"grant_title\", \"grant_desc\"]\n",
    "\n",
    "#create embeddings\n",
    "start_time = time.time()\n",
    "for col in grants_cols:\n",
    "    #replace nans with empty string\n",
    "    texts = grants_df[col].fillna(\"\").tolist()\n",
    "    embeddings = model.encode(texts)\n",
    "    \n",
    "    #add to df\n",
    "    grants_df[f\"{col}_em\"] = list(embeddings)\n",
    "    \n",
    "    print(f\"{col} embedded successfully {embeddings.shape}\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"All embeddings created for grants_df!\")\n",
    "print(f\"Total time: {elapsed_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Creation - Concatenated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funders concatenated text embedded successfully (996, 1024)\n",
      "Total time: 55.38s\n"
     ]
    }
   ],
   "source": [
    "#concatenate funder columns\n",
    "funder_text_cols = [\"activities\", \"objectives\", \"achievements_performance\", \"grant_policy\"]\n",
    "\n",
    "funders_df[\"concat_text\"] = funders_df[funder_text_cols[0]].fillna(\"\")\n",
    "for col in funder_text_cols[1:]:\n",
    "    funders_df[\"concat_text\"] += \" \" + funders_df[col].fillna(\"\")\n",
    "\n",
    "#make lowercase\n",
    "funders_df[\"concat_text\"] = funders_df[\"concat_text\"].str.lower()\n",
    "\n",
    "#create embeddings\n",
    "start_time = time.time()\n",
    "texts = funders_df[\"concat_text\"].tolist()\n",
    "embeddings = model.encode(texts)\n",
    "funders_df[\"concat_em\"] = list(embeddings)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Funders concatenated text embedded successfully {embeddings.shape}\")\n",
    "print(f\"Total time: {elapsed_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipients concatenated text embedded successfully (17169, 1024)\n",
      "Total time: 497.92s\n"
     ]
    }
   ],
   "source": [
    "#concatenate recipient columns\n",
    "recipient_text_cols = [\"recipient_activities\", \"recipient_objectives\"]\n",
    "\n",
    "recipients_df[\"concat_text\"] = recipients_df[recipient_text_cols[0]].fillna(\"\")\n",
    "for col in recipient_text_cols[1:]:\n",
    "    recipients_df[\"concat_text\"] += \" \" + recipients_df[col].fillna(\"\")\n",
    "\n",
    "#make lowercase\n",
    "recipients_df[\"concat_text\"] = recipients_df[\"concat_text\"].str.lower()\n",
    "\n",
    "#create embeddings\n",
    "start_time = time.time()\n",
    "texts = recipients_df[\"concat_text\"].tolist()\n",
    "embeddings = model.encode(texts)\n",
    "recipients_df[\"recipient_concat_em\"] = list(embeddings)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Recipients concatenated text embedded successfully {embeddings.shape}\")\n",
    "print(f\"Total time: {elapsed_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grants concatenated text embedded successfully (32816, 1024)\n",
      "Total time: 432.19s\n"
     ]
    }
   ],
   "source": [
    "#concatenate grant columns\n",
    "grant_text_cols = [\"grant_title\", \"grant_desc\"]\n",
    "\n",
    "grants_df[\"concat_text\"] = grants_df[grant_text_cols[0]].fillna(\"\")\n",
    "for col in grant_text_cols[1:]:\n",
    "    grants_df[\"concat_text\"] += \" \" + grants_df[col].fillna(\"\")\n",
    "\n",
    "#make lowercase\n",
    "grants_df[\"concat_text\"] = grants_df[\"concat_text\"].str.lower()\n",
    "\n",
    "#create embeddings\n",
    "start_time = time.time()\n",
    "texts = grants_df[\"concat_text\"].tolist()\n",
    "embeddings = model.encode(texts)\n",
    "grants_df[\"grant_concat_em\"] = list(embeddings)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Grants concatenated text embedded successfully {embeddings.shape}\")\n",
    "print(f\"Total time: {elapsed_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop concatenated text\n",
    "funders_df = funders_df.drop(columns=[\"concat_text\"])\n",
    "recipients_df = recipients_df.drop(columns=[\"concat_text\"])\n",
    "grants_df = grants_df.drop(columns=[\"concat_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create checkpoint - save dfs to pickle\n",
    "recipients_df.to_pickle(checkpoint_folder / \"recipients_df_em.pkl\")\n",
    "funders_df.to_pickle(checkpoint_folder / \"funders_df_em.pkl\")\n",
    "grants_df.to_pickle(checkpoint_folder / \"grants_df_em.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoint folder\n",
    "checkpoint_folder = Path(\"./8.1_checkpoints/\")\n",
    "\n",
    "recipients_df = pd.read_pickle(checkpoint_folder / \"recipients_df_em.pkl\")\n",
    "funders_df = pd.read_pickle(checkpoint_folder / \"funders_df_em.pkl\")\n",
    "grants_df = pd.read_pickle(checkpoint_folder / \"grants_df_em.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean Feature Creation - Single-Beneficiary Funders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When extracting grants from PDF accounts, the LLM at times failed to interpret entries properly, extracting purchase descriptions as recipient names (e.g. 'cricket balls for the Year 7 team' from a PTA's accounts) or recording vague summaries as distinct recipients (e.g. 'five various causes'). These errors are particularly prevalent in accounts from single-beneficiary funders where expenditure descriptions differ structurally from multi-recipient grant listings. I will seek to flag funders that are likely to be single-beneficiary, as this is information that can be shared with the end user if they want to check their alignment score with such a funder (e.g. 'ABC Trust seems to only give grants to one recipient, ABC School, so may not be a suitable funder to approach with an application'.)\n",
    "\n",
    "I will use some typical \"clue\" words that indicate a single-beneficiary funder (school, friends of, PTA, church, pupils) and, if these words are present in the name/activities of a funder, `is_potential_sbf` will be assigned True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check name and actitivities for giveaway single-beneficiary words\n",
    "name_check = funders_df[\"name\"].str.contains(\n",
    "    r'SCHOOL|FRIENDS OF|PTA|CHURCH|HOSPITAL',\n",
    "    case=False,\n",
    "    na=False\n",
    ")\n",
    "activities_check = funders_df[\"activities\"].str.contains(\n",
    "    r'PUPIL?',\n",
    "    case=False,\n",
    "    na=False\n",
    ")\n",
    "\n",
    "funders_df[\"is_potential_sbf\"] = name_check | activities_check\n",
    "\n",
    "print(f\"Flagged as potential SBFs: {funders_df['is_potential_sbf'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean Feature Creation - 'No Unsolicited Applications'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prospie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Scoring Logic - Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "from utils import get_table_from_supabase, build_relationship_cols, build_financial_history, extract_areas, extract_classifications\n",
    "from logic_utils import get_name_from_id, get_id_from_name, get_granularity_weight, check_if_parent, calculate_similarity_score\n",
    "\n",
    "#get keys from env\n",
    "load_dotenv()\n",
    "url = os.getenv(\"SUPABASE_URL\")\n",
    "key = os.getenv(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data from Supabase and Building Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with my EDA, I will connect to Supabase and retrieve all records, I will create one dataframe for funder information, and another for grants and recipients information. This will allow me to easily access funders' giving history, plus the classifications for both funders and recipients, to be used as part of the calculation of the alignment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tables and build dataframes\n",
    "tables = [\"funders\", \"causes\", \"areas\", \"beneficiaries\", \"grants\",\n",
    "               \"funder_causes\", \"funder_areas\", \"funder_beneficiaries\", \"funder_grants\", \n",
    "               \"financials\", \"funder_financials\",\n",
    "               \"embedding_pairs\", \"evaluation_pairs\", \"logic_pairs\",\n",
    "               \"area_hierarchy\"]\n",
    "\n",
    "for table in tables:\n",
    "    globals()[table] = get_table_from_supabase(url, key, table)\n",
    "\n",
    "#get recipients with filter\n",
    "recipients = get_table_from_supabase(url, key, \"recipients\", batch_size=50, filter_recipients=True)\n",
    "all_recipient_ids = set(recipients[\"recipient_id\"].unique())\n",
    "\n",
    "#get and filter recipient join tables\n",
    "recipient_join_tables = [\"recipient_grants\", \"recipient_areas\", \"recipient_beneficiaries\", \"recipient_causes\"]\n",
    "for table in recipient_join_tables:\n",
    "    df = get_table_from_supabase(url, key, table)\n",
    "    globals()[table] = df[df[\"recipient_id\"].isin(all_recipient_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Funders Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funders_df = funders.copy()\n",
    "\n",
    "#define table relationships for funders\n",
    "funder_rels = [\n",
    "    {\n",
    "        \"join_table\": funder_causes,\n",
    "        \"lookup_table\": causes,\n",
    "        \"key\": \"cause_id\",\n",
    "        \"value_col\": \"cause_name\",\n",
    "        \"result_col\": \"causes\"\n",
    "    },\n",
    "    {\n",
    "        \"join_table\": funder_areas,\n",
    "        \"lookup_table\": areas,\n",
    "        \"key\": \"area_id\",\n",
    "        \"value_col\": \"area_name\",\n",
    "        \"result_col\": \"areas\"\n",
    "    },\n",
    "    {\n",
    "        \"join_table\": funder_beneficiaries,\n",
    "        \"lookup_table\": beneficiaries,\n",
    "        \"key\": \"ben_id\",\n",
    "        \"value_col\": \"ben_name\",\n",
    "        \"result_col\": \"beneficiaries\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#add relationship columns\n",
    "funders_df = build_relationship_cols(funders_df, \"registered_num\", funder_rels)\n",
    "\n",
    "#round to 2 decimal places\n",
    "funders_df = funders_df.round(2)\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial History Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funders_df = build_financial_history(funders_df, \"registered_num\", funder_financials, financials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The List Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list entries\n",
    "list_entries = get_table_from_supabase(url, key, \"list_entries\")\n",
    "funder_list = get_table_from_supabase(url, key, \"funder_list\")\n",
    "list_with_info = funder_list.merge(list_entries, on=\"list_id\")\n",
    "\n",
    "#get list of entries for each funder\n",
    "list_grouped = list_with_info.groupby(\"registered_num\")[\"list_type\"].apply(list).reset_index()\n",
    "list_grouped.columns = [\"registered_num\", \"list_entries\"]\n",
    "\n",
    "#merge with funders and replace nans\n",
    "funders_df = funders_df.merge(list_grouped, on=\"registered_num\", how=\"left\")\n",
    "funders_df[\"list_entries\"] = funders_df[\"list_entries\"].apply(lambda x: x if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoint folder\n",
    "checkpoint_folder = Path(\"./10.1_checkpoints/\")\n",
    "\n",
    "#create checkpoint - save df to pickle\n",
    "# funders_df.to_pickle(checkpoint_folder / \"funders_df.pkl\")\n",
    "# print(\"Saved funders_df to checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Grants Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grants_df = grants.copy()\n",
    "\n",
    "#ddd funder info\n",
    "grants_df = grants_df.merge(funder_grants, on=\"grant_id\")\n",
    "grants_df = grants_df.merge(funders[[\"registered_num\", \"name\"]], on=\"registered_num\")\n",
    "grants_df = grants_df.rename(columns={\"name\": \"funder_name\", \"registered_num\": \"funder_num\"})\n",
    "\n",
    "#ddd recipient info  \n",
    "grants_df = grants_df.merge(recipient_grants, on=\"grant_id\")\n",
    "grants_df = grants_df.merge(recipients[[\"recipient_id\", \"recipient_name\", \"recipient_activities\", \"recipient_objectives\", \n",
    "                                        \"recipient_name_em\", \"recipient_activities_em\", \"recipient_objectives_em\", \"recipient_concat_em\", \"is_recipient\", \"recipient_extracted_class\"]], \n",
    "                        on=\"recipient_id\", \n",
    "                        how=\"left\")\n",
    "\n",
    "#define relationships for recipients\n",
    "recipient_rels = [\n",
    "    {\n",
    "        \"join_table\": recipient_areas,\n",
    "        \"lookup_table\": areas,\n",
    "        \"key\": \"area_id\",\n",
    "        \"value_col\": \"area_name\",\n",
    "        \"result_col\": \"recipient_areas\"\n",
    "    },\n",
    "    {\n",
    "        \"join_table\": recipient_causes,\n",
    "        \"lookup_table\": causes,\n",
    "        \"key\": \"cause_id\",\n",
    "        \"value_col\": \"cause_name\",\n",
    "        \"result_col\": \"recipient_causes\"\n",
    "    },\n",
    "    {\n",
    "        \"join_table\": recipient_beneficiaries,\n",
    "        \"lookup_table\": beneficiaries,\n",
    "        \"key\": \"ben_id\",\n",
    "        \"value_col\": \"ben_name\",\n",
    "        \"result_col\": \"recipient_beneficiaries\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#add relationship columns\n",
    "grants_df = build_relationship_cols(grants_df, \"recipient_id\", recipient_rels)\n",
    "\n",
    "#add source of grant\n",
    "grants_df[\"source\"] = grants_df[\"grant_id\"].apply(lambda x: \"Accounts\" if str(x).startswith(\"2\") else \"360Giving\")\n",
    "\n",
    "#round to 2 decimal places\n",
    "grants_df = grants_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create checkpoint - save df to pickle\n",
    "# grants_df.to_pickle(checkpoint_folder / \"grants_df.pkl\")\n",
    "# print(\"Saved grants_df to checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pairs Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df = logic_pairs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge to enrich with funder data\n",
    "pairs_enriched = pairs_df.merge(\n",
    "    funders_df,\n",
    "    left_on=\"funder_registered_num\",\n",
    "    right_on=\"registered_num\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_funder\")\n",
    ")\n",
    "\n",
    "#drop duplicate col\n",
    "pairs_enriched = pairs_enriched.drop(\"registered_num\", axis=1)\n",
    "\n",
    "#merge to enrich with recipient data\n",
    "pairs_enriched = pairs_enriched.merge(\n",
    "    grants_df[[\"recipient_id\", \"recipient_name\", \"recipient_activities\", \"recipient_objectives\",\n",
    "                \"recipient_areas\", \"recipient_causes\",\n",
    "                \"recipient_beneficiaries\", \"recipient_extracted_class\"]].drop_duplicates(subset=[\"recipient_id\"]),\n",
    "    on=\"recipient_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "pairs_df = pairs_enriched.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create checkpoint - save df to pickle\n",
    "# pairs_df.to_pickle(checkpoint_folder / \"pairs_df.pkl\")\n",
    "# print(\"Saved pairs_df to checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Areas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoint folder\n",
    "checkpoint_folder = Path(\"./10.1_checkpoints/\")\n",
    "\n",
    "# areas_df = areas.copy()\n",
    "# hierarchies_df = area_hierarchy.copy()\n",
    "\n",
    "#create checkpoint - save dfs to pickle\n",
    "# areas_df.to_pickle(checkpoint_folder / \"areas_df.pkl\")\n",
    "# hierarchies_df.to_pickle(checkpoint_folder / \"hierarchies_df.pkl\")\n",
    "# print(\"Saved areas_df and hierarchies_df to checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data from Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoint folder\n",
    "checkpoint_folder = Path(\"./10.1_checkpoints/\")\n",
    "\n",
    "#get checkpoint\n",
    "funders_df = pd.read_pickle(checkpoint_folder / \"funders_df.pkl\")\n",
    "grants_df = pd.read_pickle(checkpoint_folder / \"grants_df.pkl\")\n",
    "pairs_df = pd.read_pickle(checkpoint_folder / \"pairs_df.pkl\")\n",
    "areas_df = pd.read_pickle(checkpoint_folder / \"areas_df.pkl\")\n",
    "hierarchies_df = pd.read_pickle(checkpoint_folder / \"hierarchies_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of User and Funder Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the data for the recipient at index 0 in `pairs_df` as a proxy for a real user's input, to simulate the functionality of the final artefact as I build the logic. \n",
    "\n",
    "First, the user will input information about their charity (the applicant), then embeddings will be created for the inputted text data. For the purposes of this development notebook, I will simulate the user's keyword input by using extracted classifications from recipients' data, but in the final artefact, the user will be asked to enter their own keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate user's input\n",
    "user_df = pairs_df.iloc[[0]][[\"recipient_id\", \"recipient_name\", \"recipient_activities\", \"recipient_objectives\", \"recipient_areas\", \"recipient_causes\", \"recipient_beneficiaries\"]]\n",
    "user_df[\"funder_num\"] = \"1124856\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save registered numbers\n",
    "user_num = user_df[\"recipient_id\"].iloc[0]\n",
    "funder_num = user_df[\"funder_num\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Embeddings from User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-roberta-large-v1\")\n",
    "user_cols = [\"recipient_name\", \"recipient_activities\", \"recipient_objectives\"]\n",
    "\n",
    "for col in user_cols:\n",
    "    #replace nans with empty string\n",
    "    texts = user_df[col].fillna(\"\").tolist()\n",
    "    embeddings = model.encode(texts)\n",
    "    \n",
    "    #add to df\n",
    "    user_df[f\"{col}_em\"] = list(embeddings)\n",
    "\n",
    "user_df[\"concat_text\"] = user_df[user_cols[0]].fillna(\"\")\n",
    "for col in user_cols[1:]:\n",
    "    user_df[\"concat_text\"] += \" \" + user_df[col].fillna(\"\")\n",
    "\n",
    "#make lowercase\n",
    "user_df[\"concat_text\"] = user_df[\"concat_text\"].str.lower()\n",
    "\n",
    "#create embeddings\n",
    "texts = user_df[\"concat_text\"].tolist()\n",
    "embeddings = model.encode(texts)\n",
    "user_df[\"concat_em\"] = list(embeddings)\n",
    "\n",
    "#drop concatenated text\n",
    "user_df = user_df.drop(columns=[\"concat_text\"])\n",
    "\n",
    "#change recipient_ to user_\n",
    "user_df = user_df.rename(columns=lambda col: f\"user_{col[len('recipient_'):]}\" if col.startswith(\"recipient_\") else col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Extracted Classes from User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification extraction complete for user. Total time: 0.08s\n"
     ]
    }
   ],
   "source": [
    "#load classifications data\n",
    "ukcat_url = \"https://raw.githubusercontent.com/lico27/ukcat/main/data/ukcat.csv\"\n",
    "ukcat_df = pd.read_csv(ukcat_url)\n",
    "\n",
    "#define elements to process\n",
    "user_sections = [\"user_name\", \"user_objectives\", \"user_activities\"]\n",
    "keyword_data = [(user_df, user_sections, \"user\")]\n",
    "user_df[\"extracted_class\"] = user_df[\"user_areas\"].copy()\n",
    "\n",
    "#extract classifications\n",
    "for df, sections, name in keyword_data:\n",
    "    start_time = time.time()\n",
    "    df[\"user_extracted_class\"] = df.apply(lambda row: extract_classifications(row, sections, ukcat_df, areas_df), axis=1)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Classification extraction complete for {name}. Total time: {elapsed_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capitalise extracted classifications\n",
    "user_df[\"user_extracted_class\"] = user_df[\"user_extracted_class\"].apply(lambda classifications: [phrase.upper() for phrase in classifications] if isinstance(classifications, list) else [])\n",
    "\n",
    "#remove \"grant making\"\n",
    "user_df[\"user_extracted_class\"] = user_df[\"user_extracted_class\"].apply(lambda classifications: [phrase for phrase in classifications if phrase != \"GRANT MAKING\"] if isinstance(classifications, list) else [])\n",
    "\n",
    "#drop extra column\n",
    "user_df = user_df.drop(columns=[\"extracted_class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_activities</th>\n",
       "      <th>user_objectives</th>\n",
       "      <th>user_areas</th>\n",
       "      <th>user_causes</th>\n",
       "      <th>user_beneficiaries</th>\n",
       "      <th>funder_num</th>\n",
       "      <th>user_name_em</th>\n",
       "      <th>user_activities_em</th>\n",
       "      <th>user_objectives_em</th>\n",
       "      <th>concat_em</th>\n",
       "      <th>user_extracted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328729</td>\n",
       "      <td>ASYLUM AID</td>\n",
       "      <td>THE PROVISION OF LEGAL ADVICE AND REPRESENTATI...</td>\n",
       "      <td>2. OBJECTS2.1 THE CHARITY IS ESTABLISHED FOR T...</td>\n",
       "      <td>[Throughout England And Wales]</td>\n",
       "      <td>[Education/training, The Prevention Or Relief ...</td>\n",
       "      <td>[People Of A Particular Ethnic Or Racial Origi...</td>\n",
       "      <td>1124856</td>\n",
       "      <td>[-0.008021089, 0.01503942, -0.022991765, -0.02...</td>\n",
       "      <td>[-0.022860372, 0.029296849, -0.017596042, -0.0...</td>\n",
       "      <td>[0.016410686, 0.00963383, -0.04015383, -0.0136...</td>\n",
       "      <td>[-0.0008344314, -0.01810797, -0.0055338936, -0...</td>\n",
       "      <td>[THROUGHOUT ENGLAND AND WALES, ASYLUM SEEKERS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id   user_name                                    user_activities  \\\n",
       "0  328729  ASYLUM AID  THE PROVISION OF LEGAL ADVICE AND REPRESENTATI...   \n",
       "\n",
       "                                     user_objectives  \\\n",
       "0  2. OBJECTS2.1 THE CHARITY IS ESTABLISHED FOR T...   \n",
       "\n",
       "                       user_areas  \\\n",
       "0  [Throughout England And Wales]   \n",
       "\n",
       "                                         user_causes  \\\n",
       "0  [Education/training, The Prevention Or Relief ...   \n",
       "\n",
       "                                  user_beneficiaries funder_num  \\\n",
       "0  [People Of A Particular Ethnic Or Racial Origi...    1124856   \n",
       "\n",
       "                                        user_name_em  \\\n",
       "0  [-0.008021089, 0.01503942, -0.022991765, -0.02...   \n",
       "\n",
       "                                  user_activities_em  \\\n",
       "0  [-0.022860372, 0.029296849, -0.017596042, -0.0...   \n",
       "\n",
       "                                  user_objectives_em  \\\n",
       "0  [0.016410686, 0.00963383, -0.04015383, -0.0136...   \n",
       "\n",
       "                                           concat_em  \\\n",
       "0  [-0.0008344314, -0.01810797, -0.0055338936, -0...   \n",
       "\n",
       "                                user_extracted_class  \n",
       "0  [THROUGHOUT ENGLAND AND WALES, ASYLUM SEEKERS ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will next build a dataframe for the funder selected by the user, and a separate dataframe to store details of previous grants given by, and recipients of, this funder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_num</th>\n",
       "      <th>name</th>\n",
       "      <th>website</th>\n",
       "      <th>activities</th>\n",
       "      <th>objectives</th>\n",
       "      <th>income_latest</th>\n",
       "      <th>expenditure_latest</th>\n",
       "      <th>objectives_activities</th>\n",
       "      <th>achievements_performance</th>\n",
       "      <th>grant_policy</th>\n",
       "      <th>is_potential_sbf</th>\n",
       "      <th>is_on_list</th>\n",
       "      <th>is_nua</th>\n",
       "      <th>name_em</th>\n",
       "      <th>activities_em</th>\n",
       "      <th>objectives_em</th>\n",
       "      <th>objectives_activities_em</th>\n",
       "      <th>achievements_performance_em</th>\n",
       "      <th>grant_policy_em</th>\n",
       "      <th>concat_em</th>\n",
       "      <th>extracted_class</th>\n",
       "      <th>causes</th>\n",
       "      <th>areas</th>\n",
       "      <th>beneficiaries</th>\n",
       "      <th>income_history</th>\n",
       "      <th>expenditure_history</th>\n",
       "      <th>list_entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1124856</td>\n",
       "      <td>ROSA FUND</td>\n",
       "      <td>https://www.rosauk.org</td>\n",
       "      <td>ROSA IS THE FIRST UK-WIDE FUND FOR WOMEN'S INI...</td>\n",
       "      <td>THE OBJECTS OF THE CHARITY ARE TO FURTHER ANY ...</td>\n",
       "      <td>1407453.0</td>\n",
       "      <td>1372296.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[0.036068745,0.02428467,-0.026885081,-0.001224...</td>\n",
       "      <td>[0.005698055,0.011768709,-0.015513399,0.004063...</td>\n",
       "      <td>[-0.023482107,-0.02466424,0.0036000705,-0.0259...</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[0.00031545621,0.014991585,-0.003386881,0.0022...</td>\n",
       "      <td>[\"UK\",\"WALES\",\"GIRLS\",\"WOMEN\",\"CHARITY AND VCS...</td>\n",
       "      <td>[General Charitable Purposes]</td>\n",
       "      <td>[Throughout England And Wales]</td>\n",
       "      <td>[Other Charities Or Voluntary Bodies, Other De...</td>\n",
       "      <td>{2020: 155612.0, 2021: 4478996.0, 2022: 237267...</td>\n",
       "      <td>{2020: 974678.0, 2021: 2118687.0, 2022: 266530...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    registered_num       name                 website  \\\n",
       "257        1124856  ROSA FUND  https://www.rosauk.org   \n",
       "\n",
       "                                            activities  \\\n",
       "257  ROSA IS THE FIRST UK-WIDE FUND FOR WOMEN'S INI...   \n",
       "\n",
       "                                            objectives  income_latest  \\\n",
       "257  THE OBJECTS OF THE CHARITY ARE TO FURTHER ANY ...      1407453.0   \n",
       "\n",
       "     expenditure_latest objectives_activities achievements_performance  \\\n",
       "257           1372296.0                  None                     None   \n",
       "\n",
       "    grant_policy  is_potential_sbf  is_on_list  is_nua  \\\n",
       "257         None             False       False   False   \n",
       "\n",
       "                                               name_em  \\\n",
       "257  [0.036068745,0.02428467,-0.026885081,-0.001224...   \n",
       "\n",
       "                                         activities_em  \\\n",
       "257  [0.005698055,0.011768709,-0.015513399,0.004063...   \n",
       "\n",
       "                                         objectives_em  \\\n",
       "257  [-0.023482107,-0.02466424,0.0036000705,-0.0259...   \n",
       "\n",
       "                              objectives_activities_em  \\\n",
       "257  [-0.019817753,-0.00571729,0.022262126,-0.03666...   \n",
       "\n",
       "                           achievements_performance_em  \\\n",
       "257  [-0.019817753,-0.00571729,0.022262126,-0.03666...   \n",
       "\n",
       "                                       grant_policy_em  \\\n",
       "257  [-0.019817753,-0.00571729,0.022262126,-0.03666...   \n",
       "\n",
       "                                             concat_em  \\\n",
       "257  [0.00031545621,0.014991585,-0.003386881,0.0022...   \n",
       "\n",
       "                                       extracted_class  \\\n",
       "257  [\"UK\",\"WALES\",\"GIRLS\",\"WOMEN\",\"CHARITY AND VCS...   \n",
       "\n",
       "                            causes                           areas  \\\n",
       "257  [General Charitable Purposes]  [Throughout England And Wales]   \n",
       "\n",
       "                                         beneficiaries  \\\n",
       "257  [Other Charities Or Voluntary Bodies, Other De...   \n",
       "\n",
       "                                        income_history  \\\n",
       "257  {2020: 155612.0, 2021: 4478996.0, 2022: 237267...   \n",
       "\n",
       "                                   expenditure_history list_entries  \n",
       "257  {2020: 974678.0, 2021: 2118687.0, 2022: 266530...           []  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get funder data from number inputted by user\n",
    "funder_df = funders_df[funders_df[\"registered_num\"] == funder_num].copy()\n",
    "funder_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grant_title</th>\n",
       "      <th>grant_desc</th>\n",
       "      <th>amount</th>\n",
       "      <th>year</th>\n",
       "      <th>grant_id</th>\n",
       "      <th>source</th>\n",
       "      <th>grant_title_em</th>\n",
       "      <th>grant_desc_em</th>\n",
       "      <th>grant_concat_em</th>\n",
       "      <th>grant_extracted_class</th>\n",
       "      <th>funder_num</th>\n",
       "      <th>funder_grants_id</th>\n",
       "      <th>funder_name</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>recipient_grants_id</th>\n",
       "      <th>recipient_name</th>\n",
       "      <th>recipient_activities</th>\n",
       "      <th>recipient_objectives</th>\n",
       "      <th>recipient_name_em</th>\n",
       "      <th>recipient_activities_em</th>\n",
       "      <th>recipient_objectives_em</th>\n",
       "      <th>recipient_concat_em</th>\n",
       "      <th>is_recipient</th>\n",
       "      <th>recipient_extracted_class</th>\n",
       "      <th>recipient_areas</th>\n",
       "      <th>recipient_causes</th>\n",
       "      <th>recipient_beneficiaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30403</th>\n",
       "      <td>None</td>\n",
       "      <td>THE PROJECT WILL USE PART OF THE FUNDING TO PU...</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>2024</td>\n",
       "      <td>360G-RosaUK 3260-01-169603259</td>\n",
       "      <td>360Giving</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[-0.027255304,0.06465661,-0.018874627,-0.03348...</td>\n",
       "      <td>[-0.045676723,0.0343797,0.006716128,-0.0356264...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1124856</td>\n",
       "      <td>42699</td>\n",
       "      <td>ROSA FUND</td>\n",
       "      <td>invalid_2299</td>\n",
       "      <td>41509</td>\n",
       "      <td>HOLLOWAY NEIGHBOURHOOD GROUP</td>\n",
       "      <td>WE RUN THE OLD FIRE STATION - A BUSY COMMUNITY...</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.03290081,-0.003398436,-0.01662999,-0.01840...</td>\n",
       "      <td>[-0.03992139,-0.010387247,-0.04818863,-0.02297...</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[-0.057219584,-0.038814045,-0.013197874,-0.033...</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"THE FINSBURY PARK AREA\",\"SOCIAL CLUB\",\"COMMU...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      grant_title                                         grant_desc   amount  \\\n",
       "30403        None  THE PROJECT WILL USE PART OF THE FUNDING TO PU...  22500.0   \n",
       "\n",
       "       year                       grant_id     source  \\\n",
       "30403  2024  360G-RosaUK 3260-01-169603259  360Giving   \n",
       "\n",
       "                                          grant_title_em  \\\n",
       "30403  [-0.019817753,-0.00571729,0.022262126,-0.03666...   \n",
       "\n",
       "                                           grant_desc_em  \\\n",
       "30403  [-0.027255304,0.06465661,-0.018874627,-0.03348...   \n",
       "\n",
       "                                         grant_concat_em  \\\n",
       "30403  [-0.045676723,0.0343797,0.006716128,-0.0356264...   \n",
       "\n",
       "      grant_extracted_class funder_num  funder_grants_id funder_name  \\\n",
       "30403                    []    1124856             42699   ROSA FUND   \n",
       "\n",
       "       recipient_id  recipient_grants_id                recipient_name  \\\n",
       "30403  invalid_2299                41509  HOLLOWAY NEIGHBOURHOOD GROUP   \n",
       "\n",
       "                                    recipient_activities recipient_objectives  \\\n",
       "30403  WE RUN THE OLD FIRE STATION - A BUSY COMMUNITY...                 None   \n",
       "\n",
       "                                       recipient_name_em  \\\n",
       "30403  [-0.03290081,-0.003398436,-0.01662999,-0.01840...   \n",
       "\n",
       "                                 recipient_activities_em  \\\n",
       "30403  [-0.03992139,-0.010387247,-0.04818863,-0.02297...   \n",
       "\n",
       "                                 recipient_objectives_em  \\\n",
       "30403  [-0.019817753,-0.00571729,0.022262126,-0.03666...   \n",
       "\n",
       "                                     recipient_concat_em  is_recipient  \\\n",
       "30403  [-0.057219584,-0.038814045,-0.013197874,-0.033...          True   \n",
       "\n",
       "                               recipient_extracted_class recipient_areas  \\\n",
       "30403  [\"THE FINSBURY PARK AREA\",\"SOCIAL CLUB\",\"COMMU...              []   \n",
       "\n",
       "      recipient_causes recipient_beneficiaries  \n",
       "30403               []                      []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get grants for selected funder\n",
    "funder_grants_df = grants_df[grants_df[\"funder_num\"] == funder_num].copy()\n",
    "funder_grants_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Criteria (Stated Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Single-Beneficiary Funders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funder has a single beneficiary: False\n"
     ]
    }
   ],
   "source": [
    "#check if funder has a single beneficiary\n",
    "is_sbf = funder_df[\"is_potential_sbf\"].iloc[0]\n",
    "print(f\"Funder has a single beneficiary: {is_sbf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: No Unsolicited Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funder states no unsolicited applications: False\n",
      "NUA score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#check if funder states no unsolicited applications\n",
    "is_nua = funder_df[\"is_nua\"].iloc[0]\n",
    "print(f\"Funder states no unsolicited applications: {is_nua}\")\n",
    "print(f\"NUA score: {is_nua * 1.0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funder is on The List: False\n",
      "Type of List entry: None\n"
     ]
    }
   ],
   "source": [
    "#check if funder is on the list\n",
    "def check_is_on_list(funder_df):\n",
    "\n",
    "    is_on_list = funder_df[\"is_on_list\"].iloc[0]\n",
    "    reasoning = []\n",
    "\n",
    "    if is_on_list:\n",
    "        reasoning = set(funder_df[\"list_entries\"].iloc[0])\n",
    "    else:\n",
    "        reasoning = None\n",
    "        \n",
    "    return is_on_list, reasoning\n",
    "\n",
    "is_on_list, list_reasoning = check_is_on_list(funder_df)\n",
    "print(f\"Funder is on The List: {is_on_list}\")\n",
    "print(f\"Type of List entry: {list_reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Existing Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funder and user have existing relationship: True\n",
      "Funder has given 1 grant(s) to user\n"
     ]
    }
   ],
   "source": [
    "#check if funder has ever given a grant to applicant\n",
    "existing_relationship = False\n",
    "relationship = grants_df[\n",
    "    (grants_df[\"funder_num\"] == funder_num) &\n",
    "    (grants_df[\"recipient_id\"] == user_num)\n",
    "]\n",
    "num_grants = len(relationship)\n",
    "\n",
    "if num_grants > 0:\n",
    "    existing_relationship = True\n",
    "\n",
    "print(f\"Funder and user have existing relationship: {existing_relationship}\")\n",
    "print(f\"Funder has given {num_grants} grant(s) to user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Criteria (Stated Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring for areas uses hierarchical matching to account for parent-child geographic relationships. The granularity of each area affects its weight - specific locations like local authorities score higher (1.0) than broad regions (0.7). \n",
    "\n",
    "I will check three types of matches:\n",
    "- Exact matches where both funder and user state that they work in the same area\n",
    "- Hierarchical matches where the funder's area contains the user's (e.g., funder says \"Throughout England\", user works in \"Bristol\")\n",
    "- Hierarchical matches where the user's area contains the funder's specific location (e.g., user works throughout \"Africa\", funder focuses on \"Kenya\"). \n",
    "\n",
    "Each match will be weighted differently to reflect the strength of the match. The final score will average only the matched areas, ignoring non-matches, so that having some high-quality geographic alignment is valued over penalising for coverage gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Areas score: 0.70\n",
      "\n",
      "Reasoning:\n",
      "Exact match: Throughout England And Wales\n"
     ]
    }
   ],
   "source": [
    "def check_areas(funder_list, user_list, areas_df, hierarchies_df):\n",
    "    \"\"\"\n",
    "    Calculates a score based on matches between the funder's and user's stated areas.\n",
    "    \"\"\"\n",
    "\n",
    "    #convert names to ids\n",
    "    funder_ids = [get_id_from_name(name, areas_df) for name in funder_list if get_id_from_name(name, areas_df) is not None]\n",
    "    user_ids = [get_id_from_name(name, areas_df) for name in user_list if get_id_from_name(name, areas_df) is not None]\n",
    "    \n",
    "    #avoid zero division\n",
    "    if len(user_ids) == 0:\n",
    "        return 0.0, []\n",
    "    \n",
    "    #store ids as set and scores/reasoning as lists\n",
    "    funder_set = set(funder_ids)\n",
    "    scores = []\n",
    "    reasoning = []\n",
    "    \n",
    "    for user_area in user_ids:\n",
    "        user_area_name = get_name_from_id(user_area, areas_df)\n",
    "        \n",
    "        #check for exact match\n",
    "        if user_area in funder_set:\n",
    "            score = get_granularity_weight(user_area, areas_df) * 1.0\n",
    "            scores.append(score)\n",
    "            reasoning.append(f\"Exact match: {user_area_name}\")\n",
    "        \n",
    "        #check if user area is within funder area\n",
    "        else:\n",
    "            hierarchy_user_in_funder = None\n",
    "            for funder_area in funder_ids:\n",
    "                if check_if_parent(funder_area, user_area, hierarchies_df):\n",
    "                    hierarchy_user_in_funder = funder_area\n",
    "                    break\n",
    "            \n",
    "            if hierarchy_user_in_funder:\n",
    "                parent_name = get_name_from_id(hierarchy_user_in_funder, areas_df)\n",
    "                score = get_granularity_weight(hierarchy_user_in_funder, areas_df) * 0.6\n",
    "                scores.append(score)\n",
    "                reasoning.append(f\"Hierarchical match: {user_area_name} (user) within {parent_name} (funder)\")\n",
    "            \n",
    "            #check if funder area is within user area\n",
    "            else:\n",
    "                hierarchy_funder_in_user = None\n",
    "                for funder_area in funder_ids:\n",
    "                    if check_if_parent(user_area, funder_area, hierarchies_df):\n",
    "                        hierarchy_funder_in_user = funder_area\n",
    "                        break\n",
    "                \n",
    "                if hierarchy_funder_in_user:\n",
    "                    child_name = get_name_from_id(hierarchy_funder_in_user, areas_df)\n",
    "                    score = get_granularity_weight(user_area, areas_df) * 0.4\n",
    "                    scores.append(score)\n",
    "                    reasoning.append(f\"Hierarchical match: {child_name} (funder) within {user_area_name} (user)\")\n",
    "                \n",
    "                #no match\n",
    "                else:\n",
    "                    scores.append(0.0)\n",
    "                    reasoning.append(f\"No match: {user_area_name}\")\n",
    "    \n",
    "    matched_scores = [s for s in scores if s > 0]\n",
    "    if len(matched_scores) > 0:\n",
    "        score = sum(matched_scores) / len(matched_scores)\n",
    "    else:\n",
    "        score = 0.0\n",
    "    \n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get lists\n",
    "funder_areas = funder_df[\"areas\"].iloc[0].copy()\n",
    "user_areas = user_df[\"user_areas\"].iloc[0].copy()\n",
    "\n",
    "#get score and reasoning\n",
    "areas_score, areas_reasoning = check_areas(funder_areas, user_areas, areas_df, hierarchies_df)\n",
    "print(f\"Areas score: {areas_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in areas_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring for beneficiaries is simpler than for areas. I will exclude the generic \"Other Charities Or Voluntary Bodies\" as it is likely that almost all funders will fall into this category, adding noise to the scoring. I will use a hierarchical scoring approach but without the granularity weighting, as the higher level categories in this classification are too broad as to offer real value to the calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneficiaries score: 0.20\n",
      "\n",
      "Reasoning:\n",
      "Weak match: user states 'People Of A Particular Ethnic Or Racial Origin' and funder supports broad categories\n",
      "Weak match: user states 'Other Defined Groups' and funder supports broad categories\n"
     ]
    }
   ],
   "source": [
    "def check_beneficiaries(funder_list, user_list):\n",
    "    \"\"\"\n",
    "    Calculates a score based on matches between the funder's and user's stated beneficiaries.\n",
    "    \"\"\"\n",
    "\n",
    "    #define categories and filter\n",
    "    high_level_bens = {\"Other Defined Groups\", \"The General Public/mankind\"}\n",
    "    exclude_bens = {\"Other Charities Or Voluntary Bodies\"}\n",
    "    funder_bens = [ben for ben in funder_list if ben not in exclude_bens]\n",
    "    user_bens = [ben for ben in user_list if ben not in exclude_bens]\n",
    "    \n",
    "    #avoid zero division\n",
    "    if len(user_bens) == 0:\n",
    "        return 0.0, []\n",
    "    \n",
    "    #categorise funder beneficiaries\n",
    "    funder_specific = set(ben for ben in funder_bens if ben not in high_level_bens)\n",
    "    has_high_level = any(ben in high_level_bens for ben in funder_bens)\n",
    "    \n",
    "    scores = []\n",
    "    reasoning = []\n",
    "    for user_ben in user_bens:\n",
    "        if user_ben in funder_specific:\n",
    "            scores.append(1.0)\n",
    "            reasoning.append(f\"Exact match: {user_ben}\")\n",
    "        elif has_high_level:\n",
    "            scores.append(0.2)\n",
    "            reasoning.append(f\"Weak match: user states '{user_ben}' and funder supports broad categories\")\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "            reasoning.append(f\"No match: {user_ben}\")\n",
    "    \n",
    "    matched_scores = [s for s in scores if s > 0]\n",
    "    if len(matched_scores) > 0:\n",
    "        score = sum(matched_scores) / len(matched_scores)\n",
    "    else:\n",
    "        score = 0.0\n",
    "\n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get lists\n",
    "funder_beneficiaries = funder_df[\"beneficiaries\"].iloc[0].copy()\n",
    "user_beneficiaries = user_df[\"user_beneficiaries\"].iloc[0].copy()\n",
    "\n",
    "#get score and reasoning\n",
    "beneficiaries_score, beneficiaries_reasoning = check_beneficiaries(funder_beneficiaries, user_beneficiaries)\n",
    "print(f\"Beneficiaries score: {beneficiaries_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in beneficiaries_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For causes, I will exclude \"Other Charitable Purposes\" as it adds noise. However, I will not exclude \"General Charitable Purposes\" (GCP) as this is used by funders to indicate that they would be willing to consider any causes. I will use it as a fallback similar to how \"Throughout England\" works for areas. \n",
    "\n",
    "The scoring checks for exact matches between the user's and funder's causes first, which score 1.0. If no exact match exists but the funder lists GCP, this scores 0.5 as a weak indicator that the funder might support the cause. Non-matches score 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causes score: 0.60\n",
      "\n",
      "Reasoning:\n",
      "Weak match: user states 'Education/training' and funder supports general charitable purposes\n",
      "Weak match: user states 'The Prevention Or Relief Of Poverty' and funder supports general charitable purposes\n"
     ]
    }
   ],
   "source": [
    "def check_causes(funder_list, user_list):\n",
    "    \"\"\"\n",
    "    Calculates a score based on matches between the funder's and user's stated causes.\n",
    "    \"\"\"\n",
    "    #define categories and filter\n",
    "    gcp = \"General Charitable Purposes\"\n",
    "    exclude_causes = {\"Other Charitable Purposes\"}\n",
    "    funder_causes = [cause for cause in funder_list if cause not in exclude_causes]\n",
    "    user_causes = [cause for cause in user_list if cause not in exclude_causes]\n",
    "    \n",
    "    #avoid zero division\n",
    "    if len(user_causes) == 0:\n",
    "        return 0.0, []\n",
    "    \n",
    "    #categorise funder causes\n",
    "    funder_specific = set(cause for cause in funder_causes if cause != gcp)\n",
    "    has_gcp = gcp in funder_causes\n",
    "    \n",
    "    scores = []\n",
    "    reasoning = []\n",
    "    \n",
    "    for user_cause in user_causes:\n",
    "        if user_cause in funder_specific:\n",
    "            scores.append(1.0)\n",
    "            reasoning.append(f\"Exact match: {user_cause}\")\n",
    "        elif has_gcp:\n",
    "            scores.append(0.6)\n",
    "            reasoning.append(f\"Weak match: user states '{user_cause}' and funder supports general charitable purposes\")\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "            reasoning.append(f\"No match: {user_cause}\")\n",
    "    \n",
    "    matched_scores = [s for s in scores if s > 0]\n",
    "    if len(matched_scores) > 0:\n",
    "        score = sum(matched_scores) / len(matched_scores)\n",
    "    else:\n",
    "        score = 0.0\n",
    "    \n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get lists\n",
    "funder_causes = funder_df[\"causes\"].iloc[0].copy()\n",
    "user_causes = user_df[\"user_causes\"].iloc[0].copy()\n",
    "\n",
    "#get score and reasoning\n",
    "causes_score, causes_reasoning = check_causes(funder_causes, user_causes)\n",
    "print(f\"Causes score: {causes_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in causes_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity (Stated Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Text Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text semantic similarity score: 0.53\n"
     ]
    }
   ],
   "source": [
    "#get embeddings\n",
    "funder_embedding = funder_df[\"concat_em\"].iloc[0]\n",
    "user_embedding = user_df[\"concat_em\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "text_similarity_score = calculate_similarity_score(funder_embedding, user_embedding)\n",
    "print(f\"Text semantic similarity score: {text_similarity_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword similarity score: 0.44\n",
      "Eligible for keyword bonus: True\n"
     ]
    }
   ],
   "source": [
    "def check_keywords(funder_keywords, user_keywords, model):\n",
    "    \"\"\"\n",
    "    Calculates semantic similarity between funder (extracted) and user (inputted) keywords.\n",
    "    \"\"\"\n",
    "    \n",
    "    #parse json\n",
    "    if isinstance(funder_keywords, str):\n",
    "        funder_keywords = json.loads(funder_keywords)\n",
    "    if isinstance(user_keywords, str):\n",
    "        user_keywords = json.loads(user_keywords)\n",
    "    \n",
    "    #handle empty/nans\n",
    "    if not funder_keywords:\n",
    "        funder_keywords = []\n",
    "    if not user_keywords:\n",
    "        user_keywords = []\n",
    "    \n",
    "    if len(funder_keywords) == 0 or len(user_keywords) == 0:\n",
    "        return 0.0, {}, [\"No keywords to compare\"], False\n",
    "    \n",
    "    #create embeddings for each keyword\n",
    "    funder_keywords_em = {}\n",
    "    for keyword in funder_keywords:\n",
    "        embedding = model.encode(keyword)\n",
    "        funder_keywords_em[keyword] = embedding\n",
    "\n",
    "    user_keywords_em = {}\n",
    "    for keyword in user_keywords:\n",
    "        embedding = model.encode(keyword)\n",
    "        user_keywords_em[keyword] = embedding\n",
    "\n",
    "    #compare every funder keyword to every user keyword\n",
    "    all_scores = []\n",
    "    for funder_kw, funder_em in funder_keywords_em.items():\n",
    "        for user_kw, user_em in user_keywords_em.items():\n",
    "            similarity = calculate_similarity_score(funder_em, user_em)\n",
    "            all_scores.append({\n",
    "                \"funder_keyword\": funder_kw,\n",
    "                \"user_keyword\": user_kw,\n",
    "                \"similarity\": similarity\n",
    "            })\n",
    "    \n",
    "    #sort and check for bonus (matches >= 0.8)\n",
    "    all_scores.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    gets_bonus = any(match[\"similarity\"] >= 0.80 for match in all_scores)\n",
    "    \n",
    "    #get dictionary of matches >= 0.80\n",
    "    strong_matches = {}\n",
    "    for match in all_scores:\n",
    "        if match[\"similarity\"] >= 0.80:\n",
    "            key = f\"{match['funder_keyword']} & {match['user_keyword']}\"\n",
    "            strong_matches[key] = match[\"similarity\"]\n",
    "    \n",
    "    #filter to top 10 matches <= 0.80 and get average\n",
    "    scores_under_80 = [match for match in all_scores if match[\"similarity\"] < 0.80]\n",
    "    top_10 = scores_under_80[:10]\n",
    "\n",
    "    if len(top_10) > 0:\n",
    "        score = sum(match[\"similarity\"] for match in top_10) / len(top_10)\n",
    "    else:\n",
    "        score = 0.0\n",
    "    \n",
    "    #build reasoning from medium matches\n",
    "    reasoning = []\n",
    "    for match in scores_under_80[:9]:\n",
    "        reasoning.append(f\"'{match['funder_keyword']}' & '{match['user_keyword']}': {match['similarity']:.3f}\")\n",
    "    \n",
    "    return max(0.0, score), strong_matches, reasoning, gets_bonus\n",
    "\n",
    "#get keyword lists\n",
    "funder_keywords = funder_df[\"extracted_class\"].iloc[0]\n",
    "user_keywords = user_df[\"user_extracted_class\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "keyword_similarity_score, keyword_strong_matches, keyword_reasoning, keyword_gets_bonus = check_keywords(funder_keywords, user_keywords, model)\n",
    "\n",
    "print(f\"Keyword similarity score: {keyword_similarity_score:.2f}\")\n",
    "print(f\"Eligible for keyword bonus: {keyword_gets_bonus}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity (Revealed Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Name Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name (RP) similarity score: 0.45\n",
      "\n",
      "Reasoning:\n",
      "AAWAZ: 0.513\n",
      "WELSH WOMEN'S AID: 0.482\n",
      "SOLACE WOMEN'S AID: 0.479\n",
      "SOUTHAMPTON WOMEN'S AID: 0.472\n",
      "JUNO WOMEN'S AID: 0.447\n",
      "APNA HAQ: 0.443\n",
      "SIKH WOMEN'S AID: 0.434\n",
      "GUIDE ASSOCIATION: 0.426\n",
      "CARDIFF WOMEN'S AID: 0.421\n",
      "EVA WOMENS AID LTD: 0.420\n"
     ]
    }
   ],
   "source": [
    "def check_name_rp(recipients_embedding_dict, user_embedding, user_name):\n",
    "    \"\"\"\n",
    "    Calculates semantic similarity between the user's name and the names of the funder's previous recipients.\n",
    "    \"\"\"\n",
    "\n",
    "    #handle empty/nan\n",
    "    score = 0.0\n",
    "    reasoning = []\n",
    "\n",
    "    #compare every recipient name to the user's name\n",
    "    all_scores = []\n",
    "    for recipient_name, recipient_embedding in recipients_embedding_dict.items():\n",
    "        if recipient_name != user_name:\n",
    "            similarity = calculate_similarity_score(recipient_embedding, user_embedding)\n",
    "            all_scores.append({\n",
    "                \"recipient_name\": recipient_name,\n",
    "                \"similarity\": similarity\n",
    "            })\n",
    "\n",
    "    #sort and calculate average of top 10\n",
    "    all_scores.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    top_10 = all_scores[:10]\n",
    "    if len(top_10) > 0:\n",
    "        score = sum(match[\"similarity\"] for match in top_10) / len(top_10)\n",
    "    else:\n",
    "        score = 0.0\n",
    "\n",
    "    #build reasoning from top 10 matches\n",
    "    reasoning = []\n",
    "    for match in top_10:\n",
    "        reasoning.append(f\"{match['recipient_name']}: {match['similarity']:.3f}\")\n",
    "\n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get embeddings\n",
    "recipients_name_all_em = dict(zip(funder_grants_df[\"recipient_name\"], funder_grants_df[\"recipient_name_em\"]))\n",
    "user_name_em = user_df[\"user_name_em\"].iloc[0]\n",
    "user_name = user_df[\"user_name\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "name_score_rp, name_rp_reasoning = check_name_rp(recipients_name_all_em, user_name_em, user_name)\n",
    "print(f\"Name (RP) similarity score: {name_score_rp:.2f}\\n\\nReasoning:\")\n",
    "for reason in name_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Grants Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grants (RP) similarity score: 0.57\n",
      "\n",
      "Reasoning:\n",
      "REFUGEE WOMEN'S ASSOCIATION: 0.617\n",
      "ANGELS OF HOPE FOR WOMEN: 0.594\n",
      "REFUGEE WOMEN CONNECT: 0.588\n",
      "RAPE CRISIS ENGLAND & WALES: 0.582\n",
      "TRANSFORM FORTH VALLEY: 0.558\n",
      "TRANSACTUAL: 0.556\n",
      "APNA GHAR: 0.547\n",
      "BAWSO LTD: 0.545\n",
      "WOMEN FOR REFUGEE WOMEN: 0.541\n",
      "TEEN ACTION: 0.540\n"
     ]
    }
   ],
   "source": [
    "def check_grants_rp(grants_embedding_dict, user_embedding, user_name):\n",
    "    \"\"\"\n",
    "    Calculates semantic similarity between the user's text sections and the funder's previous grants.\n",
    "    \"\"\"\n",
    "\n",
    "    #handle empty/nan\n",
    "    score = 0.0\n",
    "    reasoning = []\n",
    "\n",
    "    #compare every grant to the user's text\n",
    "    all_scores = []\n",
    "    for grant_recipient_name, grant_embedding in grants_embedding_dict.items():\n",
    "        if grant_recipient_name != user_name:\n",
    "            similarity = calculate_similarity_score(grant_embedding, user_embedding)\n",
    "            all_scores.append({\n",
    "                \"grant_recipient_name\": grant_recipient_name,\n",
    "                \"similarity\": similarity\n",
    "            })\n",
    "\n",
    "    #sort and calculate average of top 10\n",
    "    all_scores.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    top_10 = all_scores[:10]\n",
    "    if len(top_10) > 0:\n",
    "        score = sum(match[\"similarity\"] for match in top_10) / len(top_10)\n",
    "    else:\n",
    "        score = 0.0\n",
    "\n",
    "    #build reasoning from top 10 matches\n",
    "    reasoning = []\n",
    "    for match in top_10:\n",
    "        reasoning.append(f\"{match['grant_recipient_name']}: {match['similarity']:.3f}\")\n",
    "\n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get embeddings\n",
    "non_empty_grants = funder_grants_df[\n",
    "    (funder_grants_df[\"grant_title\"].notna() & (funder_grants_df[\"grant_title\"] != \"\")) |\n",
    "    (funder_grants_df[\"grant_desc\"].notna() & (funder_grants_df[\"grant_desc\"] != \"\"))\n",
    "]\n",
    "\n",
    "grants_all_em = dict(zip(non_empty_grants[\"recipient_name\"], non_empty_grants[\"grant_concat_em\"]))\n",
    "user_concat_em = user_df[\"concat_em\"].iloc[0]\n",
    "user_name = user_df[\"user_name\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "grants_rp_score, grants_rp_reasoning = check_grants_rp(grants_all_em, user_concat_em, user_name)\n",
    "print(f\"Grants (RP) similarity score: {grants_rp_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in grants_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Recipients Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipients (RP) similarity score: 0.66\n",
      "\n",
      "Reasoning:\n",
      "VOICE OF DOMESTIC WORKERS: 0.717\n",
      "SUFFOLK REFUGEE SUPPORT: 0.699\n",
      "WOMEN FOR REFUGEE WOMEN: 0.695\n",
      "AFRICAN WOMEN'S CARE: 0.667\n",
      "SAFETY4SISTERS NORTH WEST: 0.664\n",
      "LESBIAN IMMIGRATION SUPPORT GROUP: 0.656\n",
      "BASIS YORKSHIRE LTD: 0.624\n",
      "MOTHER AND CHILD WELFARE ORGANISATION: 0.623\n",
      "SANDWELL AFRICAN WOMEN ASSOCIATION: 0.618\n",
      "ETHIOPIAN WOMEN'S EMPOWERMENT GROUP: 0.617\n"
     ]
    }
   ],
   "source": [
    "def check_recipients_rp(recipients_embedding_dict, user_embedding, user_name):\n",
    "    \"\"\"\n",
    "    Calculates semantic similarity between the user's text sections and those of the funder's previous recipients.\n",
    "    \"\"\"\n",
    "\n",
    "    #handle empty/nan\n",
    "    score = 0.0\n",
    "    reasoning = []\n",
    "\n",
    "    #compare every recipient's text to the user's text\n",
    "    all_scores = []\n",
    "    for recipient_name, recipient_embedding in recipients_embedding_dict.items():\n",
    "        if recipient_name != user_name:\n",
    "            similarity = calculate_similarity_score(recipient_embedding, user_embedding)\n",
    "            all_scores.append({\n",
    "                \"grant_recipient_name\": recipient_name,\n",
    "                \"similarity\": similarity\n",
    "            })\n",
    "\n",
    "    #sort and calculate average of top 10\n",
    "    all_scores.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    top_10 = all_scores[:10]\n",
    "    if len(top_10) > 0:\n",
    "        score = sum(match[\"similarity\"] for match in top_10) / len(top_10)\n",
    "    else:\n",
    "        score = 0.0\n",
    "\n",
    "    #build reasoning from top 10 matches\n",
    "    reasoning = []\n",
    "    for match in top_10:\n",
    "        reasoning.append(f\"{match['grant_recipient_name']}: {match['similarity']:.3f}\")\n",
    "\n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get embeddings\n",
    "recipients_all_em = dict(zip(funder_grants_df[\"recipient_name\"], funder_grants_df[\"recipient_concat_em\"]))\n",
    "user_concat_em = user_df[\"concat_em\"].iloc[0]\n",
    "user_name = user_df[\"user_name\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "recipients_rp_score, recipients_rp_reasoning = check_recipients_rp(recipients_all_em, user_concat_em, user_name)\n",
    "print(f\"Recipients (RP) similarity score: {recipients_rp_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in recipients_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalties and Bonuses (Stated Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: SBF Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-beneficiary penalty: *1.0\n"
     ]
    }
   ],
   "source": [
    "sbf_penalty = 0.2 if is_sbf else 1.0\n",
    "print(f\"Single-beneficiary penalty: *{sbf_penalty}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Keywords Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 strong keyword matches:\n",
      "HEALTH & HEALTH: 1.00\n",
      "HEALTH & MENTAL HEALTH: 0.82\n",
      "Keywords bonus: *1.15\n"
     ]
    }
   ],
   "source": [
    "def calculate_keywords_bonus(strong_matches, ukcat_df):\n",
    "    \"\"\"\n",
    "    Calculates bonus based on keyword matches. Only runs if keywords with semantic scores above 0.8 exist.\n",
    "    \"\"\"\n",
    "\n",
    "    #weight by specificity of ukcat level\n",
    "    level_weights = {\n",
    "        1: 0.3, \n",
    "        2: 0.7, \n",
    "        3: 1.0\n",
    "    }\n",
    "    \n",
    "    weighted_scores = []\n",
    "    for keyword, score in strong_matches.items():\n",
    "        #find keyword in ukcat_df\n",
    "        match = ukcat_df[ukcat_df['tag'].str.upper() == keyword.upper()]\n",
    "        \n",
    "        if not match.empty:\n",
    "            level = match.iloc[0]['level']\n",
    "            weighted_score = score * level_weights.get(level, 1.0)\n",
    "        else:\n",
    "            weighted_score = score * 0.3\n",
    "        \n",
    "        weighted_scores.append(weighted_score)\n",
    "    \n",
    "    avg_weighted = sum(weighted_scores) / len(weighted_scores)\n",
    "    \n",
    "    #calculate bonus\n",
    "    bonus = 1.1 + (avg_weighted * 0.2)\n",
    "    bonus = min(max(bonus, 1.1), 1.3)\n",
    "    \n",
    "    return bonus\n",
    "\n",
    "#get bonus and reasoning\n",
    "keywords_bonus = calculate_keywords_bonus(keyword_strong_matches, ukcat_df)\n",
    "\n",
    "print(f\"{len(keyword_strong_matches)} strong keyword matches:\")\n",
    "for match, score in keyword_strong_matches.items():\n",
    "    print(f\"{match}: {score:.2f}\")\n",
    "print(f\"Keywords bonus: *{keywords_bonus:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Existing Relationship Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last gift given in 2013 (12 years ago)\n",
      "Relationship bonus: *1.1\n"
     ]
    }
   ],
   "source": [
    "def calculate_relationship_bonus(relationship_df):\n",
    "    \"\"\"\n",
    "    Calculates time since last grant and calculates a bonus. Only runs if there is a relationship.\n",
    "    \"\"\"\n",
    "\n",
    "    #get time lapsed since last gift\n",
    "    last_grant_year = relationship_df[\"year\"].max()\n",
    "    current_year = datetime.now().year\n",
    "    time_lapsed = current_year - last_grant_year\n",
    "    \n",
    "    #assign bands\n",
    "    if time_lapsed <= 2:\n",
    "        bonus = 1.5\n",
    "    elif time_lapsed <= 3:\n",
    "        bonus = 1.4\n",
    "    elif time_lapsed <= 5:\n",
    "        bonus = 1.3\n",
    "    elif time_lapsed <= 10:\n",
    "        bonus = 1.2\n",
    "    else:\n",
    "        bonus = 1.1\n",
    "    \n",
    "    #add uplift for recurring relationship\n",
    "    num_grants = len(relationship_df)\n",
    "    if num_grants >= 5:\n",
    "        bonus += 0.1\n",
    "    \n",
    "    return time_lapsed, bonus, last_grant_year\n",
    "\n",
    "#get bonus and reasoning\n",
    "time_lapsed, relationship_bonus, last_grant_year = calculate_relationship_bonus(relationship)\n",
    "\n",
    "print(f\"Last gift given in {last_grant_year} ({time_lapsed} years ago)\")\n",
    "print(f\"Relationship bonus: *{relationship_bonus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalties and Bonuses (Revealed Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: Areas Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Areas score: 1.14\n",
      "\n",
      "Reasoning:\n",
      "Manchester City: 23 grants (2.2%)\n",
      "Newcastle Upon Tyne City: 21 grants (2.0%)\n",
      "Scotland: 21 grants (2.0%)\n",
      "Birmingham City: 20 grants (1.9%)\n",
      "South Tyneside: 19 grants (1.8%)\n",
      "Rochdale: 17 grants (1.6%)\n",
      "Gateshead: 17 grants (1.6%)\n",
      "Northern Ireland: 16 grants (1.5%)\n",
      "Sandwell: 16 grants (1.5%)\n",
      "Haringey: 15 grants (1.4%)\n"
     ]
    }
   ],
   "source": [
    "def calculate_areas_bonus_rp(funder_grants_df, user_areas, areas_df, hierarchies_df):\n",
    "    \"\"\"\n",
    "    Calculates a bonus based on how well the user's areas match the funder's recipient's areas.\n",
    "    \"\"\"\n",
    "\n",
    "    if funder_grants_df.empty:\n",
    "        return 0.0, [\"No grants history available\"]\n",
    "\n",
    "    #get unique areas from recipients\n",
    "    all_areas = []\n",
    "    for areas_list in funder_grants_df[\"recipient_areas\"]:\n",
    "        if isinstance(areas_list, list):\n",
    "            all_areas.extend(areas_list)\n",
    "\n",
    "    if len(all_areas) == 0:\n",
    "        return 0.0, [\"No area data available\"]\n",
    "\n",
    "    recipient_areas = list(set(all_areas))\n",
    "\n",
    "    #check areas\n",
    "    match_score, _ = check_areas(recipient_areas, user_areas, areas_df, hierarchies_df)\n",
    "\n",
    "    #convert to bonus multiplier\n",
    "    bonus = 1.0 + (match_score * 0.2)\n",
    "\n",
    "    #get reasoning from top 10 (low level tiers only)\n",
    "    area_count = {}\n",
    "    for area_name in all_areas:\n",
    "        area_id = get_id_from_name(area_name, areas_df)\n",
    "        if area_id:\n",
    "            granularity = get_granularity_weight(area_id, areas_df)\n",
    "            if granularity >= 0.9:\n",
    "                area_count[area_name] = area_count.get(area_name, 0) + 1\n",
    "\n",
    "    if len(area_count) == 0:\n",
    "        reasoning = [\"Only broad geographic areas found\"]\n",
    "    else:\n",
    "        sorted_areas = sorted(area_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        total_low_level = sum(area_count.values())\n",
    "\n",
    "        reasoning = []\n",
    "        for area_name, count in sorted_areas[:10]:\n",
    "            percentage = (count / total_low_level) * 100\n",
    "            reasoning.append(f\"{area_name}: {count} grants ({percentage:.1f}%)\")\n",
    "\n",
    "    return bonus, reasoning\n",
    "\n",
    "#get list\n",
    "user_areas = user_df[\"user_areas\"].iloc[0].copy()\n",
    "\n",
    "#get bonus and reasoning\n",
    "areas_rp_bonus, areas_rp_reasoning = calculate_areas_bonus_rp(funder_grants_df, user_areas, areas_df, hierarchies_df)\n",
    "print(f\"Areas score: {areas_rp_bonus:.2f}\\n\\nReasoning:\")\n",
    "for reason in areas_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 17: Keywords Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords (RP) bonus: *1.10\n",
      "\n",
      "Reasoning:\n",
      "EDUCATION: 321 occurrences\n",
      "INDIVIDUAL POVERTY: 251 occurrences\n",
      "HEALTH: 247 occurrences\n",
      "TRAINING: 219 occurrences\n",
      "ADVICE AND INDIVIDUAL ADVOCACY: 183 occurrences\n",
      "ABUSE: 157 occurrences\n",
      "POLICY CAMPAIGNING AND ADVOCACY: 110 occurrences\n",
      "MENTAL HEALTH: 96 occurrences\n",
      "ASYLUM SEEKERS AND REFUGEES: 73 occurrences\n",
      "MIGRANTS: 52 occurrences\n"
     ]
    }
   ],
   "source": [
    "def calculate_keywords_bonus_rp(funder_grants_df, user_keywords):\n",
    "    \"\"\"\n",
    "    Calculates a bonus based on exact keyword matches between user and funder's recipients.\n",
    "    \"\"\"\n",
    "\n",
    "    if funder_grants_df.empty:\n",
    "        return 1.0, [\"No grants history available\"]\n",
    "\n",
    "    #parse json\n",
    "    if isinstance(user_keywords, str):\n",
    "        user_keywords = json.loads(user_keywords)\n",
    "    if not user_keywords:\n",
    "        user_keywords = []\n",
    "\n",
    "    if len(user_keywords) == 0:\n",
    "        return 1.0, [\"No user keywords to match\"]\n",
    "\n",
    "    #get all recipient keywords\n",
    "    all_recipient_keywords = []\n",
    "    for recipient_keywords in funder_grants_df[\"recipient_extracted_class\"]:\n",
    "        if isinstance(recipient_keywords, str):\n",
    "            recipient_keywords = json.loads(recipient_keywords)\n",
    "        if recipient_keywords:\n",
    "            all_recipient_keywords.extend(recipient_keywords)\n",
    "\n",
    "    if len(all_recipient_keywords) == 0:\n",
    "        return 1.0, [\"No recipient keywords available\"]\n",
    "\n",
    "    #find exact matches and count frequency\n",
    "    matched_keywords = {}\n",
    "    user_keywords_matched = set()\n",
    "\n",
    "    for user_kw in user_keywords:\n",
    "        if user_kw in all_recipient_keywords:\n",
    "            user_keywords_matched.add(user_kw)\n",
    "            matched_keywords[user_kw] = matched_keywords.get(user_kw, 0) + all_recipient_keywords.count(user_kw)\n",
    "\n",
    "    #calculate match percentage\n",
    "    match_percentage = len(user_keywords_matched) / len(user_keywords)\n",
    "\n",
    "    #calculate bonus\n",
    "    if match_percentage >= 0.9:\n",
    "        bonus = 1.1\n",
    "    elif match_percentage >= 0.5:\n",
    "        bonus = 1.05\n",
    "    else:\n",
    "        bonus = 1.0 + (match_percentage * 0.2)\n",
    "\n",
    "    #build reasoning from top 10\n",
    "    if len(matched_keywords) == 0:\n",
    "        reasoning = [\"No exact keyword matches found\"]\n",
    "    else:\n",
    "        sorted_matches = sorted(matched_keywords.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        reasoning = []\n",
    "        for keyword, count in sorted_matches[:10]:\n",
    "            reasoning.append(f\"{keyword}: {count} occurrences\")\n",
    "\n",
    "    return bonus, reasoning\n",
    "\n",
    "#get list\n",
    "user_keywords = user_df[\"user_extracted_class\"].iloc[0]\n",
    "\n",
    "#get bonus and reasoning\n",
    "keywords_rp_bonus, keywords_rp_reasoning = calculate_keywords_bonus_rp(funder_grants_df, user_keywords)\n",
    "print(f\"Keywords (RP) bonus: *{keywords_rp_bonus:.2f}\\n\\nReasoning:\")\n",
    "for reason in keywords_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 18: Low-Variance Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low variance (RP) penalty: *1.00\n"
     ]
    }
   ],
   "source": [
    "def calculate_lv_penalty(funder_grants_df):\n",
    "    \"\"\"\n",
    "    Identifies low variance in a funder's previous giving and calculates a penalty.\n",
    "    \"\"\"\n",
    "\n",
    "    #skip funders with low giving history\n",
    "    if len(funder_grants_df) < 10:\n",
    "        return 1.0\n",
    "\n",
    "    total_grants = len(funder_grants_df)\n",
    "    unique_recipients = funder_grants_df['recipient_name'].nunique()\n",
    "    \n",
    "    #find proportion of grants to unique recipients\n",
    "    variance_proportion = unique_recipients / total_grants\n",
    "    \n",
    "    #calculate penalty\n",
    "    if variance_proportion < 0.3:\n",
    "        penalty = 0.7\n",
    "    else:\n",
    "        penalty = 1.0\n",
    "    \n",
    "    return penalty\n",
    "\n",
    "#get penalty\n",
    "lv_penalty = calculate_lv_penalty(funder_grants_df)\n",
    "print(f\"Low variance (RP) penalty: *{lv_penalty:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prospie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Scoring Logic - Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "from utils import get_table_from_supabase, build_relationship_cols, build_financial_history\n",
    "from logic_utils import get_name_from_id, get_id_from_name, get_granularity_weight, check_if_parent, calculate_similarity_score\n",
    "\n",
    "#get keys from env\n",
    "load_dotenv()\n",
    "url = os.getenv(\"SUPABASE_URL\")\n",
    "key = os.getenv(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data from Supabase and Building Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with my EDA, I will connect to Supabase and retrieve all records, I will create one dataframe for funder information, and another for grants and recipients information. This will allow me to easily access funders' giving history, plus the classifications for both funders and recipients, to be used as part of the calculation of the alignment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get tables and build dataframes\n",
    "tables = [\"funders\", \"causes\", \"areas\", \"beneficiaries\", \"grants\",\n",
    "               \"funder_causes\", \"funder_areas\", \"funder_beneficiaries\", \"funder_grants\", \n",
    "               \"financials\", \"funder_financials\",\n",
    "               \"embedding_pairs\", \"evaluation_pairs\", \"logic_pairs\",\n",
    "               \"area_hierarchy\"]\n",
    "\n",
    "for table in tables:\n",
    "    globals()[table] = get_table_from_supabase(url, key, table)\n",
    "\n",
    "#get recipients with filter\n",
    "recipients = get_table_from_supabase(url, key, \"recipients\", batch_size=50, filter_recipients=True)\n",
    "all_recipient_ids = set(recipients[\"recipient_id\"].unique())\n",
    "\n",
    "#get and filter recipient join tables\n",
    "recipient_join_tables = [\"recipient_grants\", \"recipient_areas\", \"recipient_beneficiaries\", \"recipient_causes\"]\n",
    "for table in recipient_join_tables:\n",
    "    df = get_table_from_supabase(url, key, table)\n",
    "    globals()[table] = df[df[\"recipient_id\"].isin(all_recipient_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Funders Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funders_df = funders.copy()\n",
    "\n",
    "#define table relationships for funders\n",
    "funder_rels = [\n",
    "    {\n",
    "        \"join_table\": funder_causes,\n",
    "        \"lookup_table\": causes,\n",
    "        \"key\": \"cause_id\",\n",
    "        \"value_col\": \"cause_name\",\n",
    "        \"result_col\": \"causes\"\n",
    "    },\n",
    "    {\n",
    "        \"join_table\": funder_areas,\n",
    "        \"lookup_table\": areas,\n",
    "        \"key\": \"area_id\",\n",
    "        \"value_col\": \"area_name\",\n",
    "        \"result_col\": \"areas\"\n",
    "    },\n",
    "    {\n",
    "        \"join_table\": funder_beneficiaries,\n",
    "        \"lookup_table\": beneficiaries,\n",
    "        \"key\": \"ben_id\",\n",
    "        \"value_col\": \"ben_name\",\n",
    "        \"result_col\": \"beneficiaries\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#add relationship columns\n",
    "funders_df = build_relationship_cols(funders_df, \"registered_num\", funder_rels)\n",
    "\n",
    "#round to 2 decimal places\n",
    "funders_df = funders_df.round(2)\n",
    "pd.set_option(\"display.float_format\", \"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial History Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funders_df = build_financial_history(funders_df, \"registered_num\", funder_financials, financials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The List Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list entries\n",
    "list_entries = get_table_from_supabase(url, key, \"list_entries\")\n",
    "funder_list = get_table_from_supabase(url, key, \"funder_list\")\n",
    "list_with_info = funder_list.merge(list_entries, on=\"list_id\")\n",
    "\n",
    "#get list of entries for each funder\n",
    "list_grouped = list_with_info.groupby(\"registered_num\")[\"list_type\"].apply(list).reset_index()\n",
    "list_grouped.columns = [\"registered_num\", \"list_entries\"]\n",
    "\n",
    "#merge with funders and replace nans\n",
    "funders_df = funders_df.merge(list_grouped, on=\"registered_num\", how=\"left\")\n",
    "funders_df[\"list_entries\"] = funders_df[\"list_entries\"].apply(lambda x: x if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoint folder\n",
    "checkpoint_folder = Path(\"./10.1_checkpoints/\")\n",
    "\n",
    "#create checkpoint - save df to pickle\n",
    "# funders_df.to_pickle(checkpoint_folder / \"funders_df.pkl\")\n",
    "# print(\"Saved funders_df to checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Grants Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grants_df = grants.copy()\n",
    "\n",
    "#ddd funder info\n",
    "grants_df = grants_df.merge(funder_grants, on=\"grant_id\")\n",
    "grants_df = grants_df.merge(funders[[\"registered_num\", \"name\"]], on=\"registered_num\")\n",
    "grants_df = grants_df.rename(columns={\"name\": \"funder_name\", \"registered_num\": \"funder_num\"})\n",
    "\n",
    "#ddd recipient info  \n",
    "grants_df = grants_df.merge(recipient_grants, on=\"grant_id\")\n",
    "grants_df = grants_df.merge(recipients[[\"recipient_id\", \"recipient_name\", \"recipient_activities\", \"recipient_objectives\", \n",
    "                                        \"recipient_name_em\", \"recipient_activities_em\", \"recipient_objectives_em\", \"recipient_concat_em\", \"is_recipient\", \"recipient_extracted_class\"]], \n",
    "                        on=\"recipient_id\", \n",
    "                        how=\"left\")\n",
    "\n",
    "#define relationships for recipients\n",
    "recipient_rels = [\n",
    "    {\n",
    "        \"join_table\": recipient_areas,\n",
    "        \"lookup_table\": areas,\n",
    "        \"key\": \"area_id\",\n",
    "        \"value_col\": \"area_name\",\n",
    "        \"result_col\": \"recipient_areas\"\n",
    "    },\n",
    "    {\n",
    "        \"join_table\": recipient_causes,\n",
    "        \"lookup_table\": causes,\n",
    "        \"key\": \"cause_id\",\n",
    "        \"value_col\": \"cause_name\",\n",
    "        \"result_col\": \"recipient_causes\"\n",
    "    },\n",
    "    {\n",
    "        \"join_table\": recipient_beneficiaries,\n",
    "        \"lookup_table\": beneficiaries,\n",
    "        \"key\": \"ben_id\",\n",
    "        \"value_col\": \"ben_name\",\n",
    "        \"result_col\": \"recipient_beneficiaries\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#add relationship columns\n",
    "grants_df = build_relationship_cols(grants_df, \"recipient_id\", recipient_rels)\n",
    "\n",
    "#add source of grant\n",
    "grants_df[\"source\"] = grants_df[\"grant_id\"].apply(lambda x: \"Accounts\" if str(x).startswith(\"2\") else \"360Giving\")\n",
    "\n",
    "#round to 2 decimal places\n",
    "grants_df = grants_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create checkpoint - save df to pickle\n",
    "# grants_df.to_pickle(checkpoint_folder / \"grants_df.pkl\")\n",
    "# print(\"Saved grants_df to checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pairs Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df = logic_pairs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge to enrich with funder data\n",
    "pairs_enriched = pairs_df.merge(\n",
    "    funders_df,\n",
    "    left_on=\"funder_registered_num\",\n",
    "    right_on=\"registered_num\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_funder\")\n",
    ")\n",
    "\n",
    "#drop duplicate col\n",
    "pairs_enriched = pairs_enriched.drop(\"registered_num\", axis=1)\n",
    "\n",
    "#merge to enrich with recipient data\n",
    "pairs_enriched = pairs_enriched.merge(\n",
    "    grants_df[[\"recipient_id\", \"recipient_name\", \"recipient_activities\", \"recipient_objectives\",\n",
    "                \"recipient_areas\", \"recipient_causes\",\n",
    "                \"recipient_beneficiaries\", \"recipient_extracted_class\"]].drop_duplicates(subset=[\"recipient_id\"]),\n",
    "    on=\"recipient_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "pairs_df = pairs_enriched.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create checkpoint - save df to pickle\n",
    "# pairs_df.to_pickle(checkpoint_folder / \"pairs_df.pkl\")\n",
    "# print(\"Saved pairs_df to checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Areas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoint folder\n",
    "checkpoint_folder = Path(\"./10.1_checkpoints/\")\n",
    "\n",
    "# areas_df = areas.copy()\n",
    "# hierarchies_df = area_hierarchy.copy()\n",
    "\n",
    "#create checkpoint - save dfs to pickle\n",
    "# areas_df.to_pickle(checkpoint_folder / \"areas_df.pkl\")\n",
    "# hierarchies_df.to_pickle(checkpoint_folder / \"hierarchies_df.pkl\")\n",
    "# print(\"Saved areas_df and hierarchies_df to checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data from Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get checkpoint folder\n",
    "checkpoint_folder = Path(\"./10.1_checkpoints/\")\n",
    "\n",
    "#get checkpoint\n",
    "funders_df = pd.read_pickle(checkpoint_folder / \"funders_df.pkl\")\n",
    "grants_df = pd.read_pickle(checkpoint_folder / \"grants_df.pkl\")\n",
    "pairs_df = pd.read_pickle(checkpoint_folder / \"pairs_df.pkl\")\n",
    "areas_df = pd.read_pickle(checkpoint_folder / \"areas_df.pkl\")\n",
    "hierarchies_df = pd.read_pickle(checkpoint_folder / \"hierarchies_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of User and Funder Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the data for the recipient at index 0 in `pairs_df` as a proxy for a real user's input, to simulate the functionality of the final artefact as I build the logic. \n",
    "\n",
    "First, the user will input information about their charity (the applicant), then embeddings will be created for the inputted text data. For the purposes of this development notebook, I will simulate the user's keyword input by using extracted classifications from recipients' data, but in the final artefact, the user will be asked to enter their own keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulate user's input\n",
    "user_df = pairs_df.iloc[[7]][[\"recipient_id\", \"recipient_name\", \"recipient_activities\", \"recipient_objectives\", \"recipient_areas\", \"recipient_causes\", \"recipient_beneficiaries\", \"recipient_extracted_class\"]]\n",
    "user_df[\"funder_num\"] = \"1004043\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save registered numbers\n",
    "user_num = user_df[\"recipient_id\"].iloc[0]\n",
    "funder_num = user_df[\"funder_num\"].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Embeddings from User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-roberta-large-v1\")\n",
    "user_cols = [\"recipient_name\", \"recipient_activities\", \"recipient_objectives\"]\n",
    "\n",
    "for col in user_cols:\n",
    "    #replace nans with empty string\n",
    "    texts = user_df[col].fillna(\"\").tolist()\n",
    "    embeddings = model.encode(texts)\n",
    "    \n",
    "    #add to df\n",
    "    user_df[f\"{col}_em\"] = list(embeddings)\n",
    "\n",
    "user_df[\"concat_text\"] = user_df[user_cols[0]].fillna(\"\")\n",
    "for col in user_cols[1:]:\n",
    "    user_df[\"concat_text\"] += \" \" + user_df[col].fillna(\"\")\n",
    "\n",
    "#make lowercase\n",
    "user_df[\"concat_text\"] = user_df[\"concat_text\"].str.lower()\n",
    "\n",
    "#create embeddings\n",
    "texts = user_df[\"concat_text\"].tolist()\n",
    "embeddings = model.encode(texts)\n",
    "user_df[\"concat_em\"] = list(embeddings)\n",
    "\n",
    "#drop concatenated text\n",
    "user_df = user_df.drop(columns=[\"concat_text\"])\n",
    "\n",
    "#change recipient_ to user_\n",
    "user_df = user_df.rename(columns=lambda col: f\"user_{col[len('recipient_'):]}\" if col.startswith(\"recipient_\") else col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_activities</th>\n",
       "      <th>user_objectives</th>\n",
       "      <th>user_areas</th>\n",
       "      <th>user_causes</th>\n",
       "      <th>user_beneficiaries</th>\n",
       "      <th>user_extracted_class</th>\n",
       "      <th>funder_num</th>\n",
       "      <th>user_name_em</th>\n",
       "      <th>user_activities_em</th>\n",
       "      <th>user_objectives_em</th>\n",
       "      <th>concat_em</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1059465</td>\n",
       "      <td>LEDBURY POETRY</td>\n",
       "      <td>THE CHARITY SEEKS TO ADVANCE THE EDUCATION OF ...</td>\n",
       "      <td>TO ADVANCE THE EDUCATION OF THE PUBLIC IN THE ...</td>\n",
       "      <td>[Gloucestershire, Shropshire, Herefordshire, W...</td>\n",
       "      <td>[Education/training, Arts/culture/heritage/sci...</td>\n",
       "      <td>[Children/young People, Elderly/old People, Pe...</td>\n",
       "      <td>[\"ARTS\",\"FESTIVAL\",\"CHILDREN\",\"OLDER PEOPLE\",\"...</td>\n",
       "      <td>1004043</td>\n",
       "      <td>[0.020434346, 0.014396212, -0.052079026, 0.004...</td>\n",
       "      <td>[0.014336084, 0.0039388468, -0.038242634, 0.00...</td>\n",
       "      <td>[0.030727182, 0.012970083, -0.042486615, -0.00...</td>\n",
       "      <td>[0.016563373, -0.03815507, -0.014847847, 0.038...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       user_name                                    user_activities  \\\n",
       "7  1059465  LEDBURY POETRY  THE CHARITY SEEKS TO ADVANCE THE EDUCATION OF ...   \n",
       "\n",
       "                                     user_objectives  \\\n",
       "7  TO ADVANCE THE EDUCATION OF THE PUBLIC IN THE ...   \n",
       "\n",
       "                                          user_areas  \\\n",
       "7  [Gloucestershire, Shropshire, Herefordshire, W...   \n",
       "\n",
       "                                         user_causes  \\\n",
       "7  [Education/training, Arts/culture/heritage/sci...   \n",
       "\n",
       "                                  user_beneficiaries  \\\n",
       "7  [Children/young People, Elderly/old People, Pe...   \n",
       "\n",
       "                                user_extracted_class funder_num  \\\n",
       "7  [\"ARTS\",\"FESTIVAL\",\"CHILDREN\",\"OLDER PEOPLE\",\"...    1004043   \n",
       "\n",
       "                                        user_name_em  \\\n",
       "7  [0.020434346, 0.014396212, -0.052079026, 0.004...   \n",
       "\n",
       "                                  user_activities_em  \\\n",
       "7  [0.014336084, 0.0039388468, -0.038242634, 0.00...   \n",
       "\n",
       "                                  user_objectives_em  \\\n",
       "7  [0.030727182, 0.012970083, -0.042486615, -0.00...   \n",
       "\n",
       "                                           concat_em  \n",
       "7  [0.016563373, -0.03815507, -0.014847847, 0.038...  "
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will next build a dataframe for the funder selected by the user, and a separate dataframe to store details of previous grants given by, and recipients of, this funder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>registered_num</th>\n",
       "      <th>name</th>\n",
       "      <th>website</th>\n",
       "      <th>activities</th>\n",
       "      <th>objectives</th>\n",
       "      <th>income_latest</th>\n",
       "      <th>expenditure_latest</th>\n",
       "      <th>objectives_activities</th>\n",
       "      <th>achievements_performance</th>\n",
       "      <th>grant_policy</th>\n",
       "      <th>is_potential_sbf</th>\n",
       "      <th>is_on_list</th>\n",
       "      <th>is_nua</th>\n",
       "      <th>name_em</th>\n",
       "      <th>activities_em</th>\n",
       "      <th>objectives_em</th>\n",
       "      <th>objectives_activities_em</th>\n",
       "      <th>achievements_performance_em</th>\n",
       "      <th>grant_policy_em</th>\n",
       "      <th>concat_em</th>\n",
       "      <th>extracted_class</th>\n",
       "      <th>causes</th>\n",
       "      <th>areas</th>\n",
       "      <th>beneficiaries</th>\n",
       "      <th>income_history</th>\n",
       "      <th>expenditure_history</th>\n",
       "      <th>list_entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1004043</td>\n",
       "      <td>ELMLEY FOUNDATION</td>\n",
       "      <td>https://www.elmley.org.uk</td>\n",
       "      <td>GRANTMAKING TO THE ARTS IN HEREFORDSHIRE AND W...</td>\n",
       "      <td>THE ADVANCEMENT OF EDUCATION BY PROMOTING THE ...</td>\n",
       "      <td>503017.0</td>\n",
       "      <td>427809.0</td>\n",
       "      <td>THE MAIN OBJECT OF THE ALLEY FOUNDATION IS THE...</td>\n",
       "      <td>DURING THE YEAR 55 (2023 - 46) GRANTS WERE PAI...</td>\n",
       "      <td>THE FOUNDATION RUNS A MAIN GRANTS PROGRAMMED A...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.013806051,0.004415134,-0.039929647,-0.0218...</td>\n",
       "      <td>[-0.00052015856,0.05774775,-0.019198824,0.0320...</td>\n",
       "      <td>[0.024830407,0.02097424,-0.024029357,-0.000506...</td>\n",
       "      <td>[-0.010489335,0.04122564,-0.05875264,-0.031378...</td>\n",
       "      <td>[0.0078094695,0.030438136,-0.021327853,-0.0223...</td>\n",
       "      <td>[-0.017348576,0.040816862,-0.036546793,-0.0099...</td>\n",
       "      <td>[0.0057244967,0.0213804,0.00524321,-0.01299309...</td>\n",
       "      <td>[\"HEREFORD\",\"WORCESTER\",\"WORCESTERSHIRE\",\"ARTS...</td>\n",
       "      <td>[Arts/culture/heritage/science]</td>\n",
       "      <td>[Herefordshire, Worcestershire]</td>\n",
       "      <td>[Other Defined Groups]</td>\n",
       "      <td>{2020: 420914.0, 2021: 247044.0, 2022: 396098....</td>\n",
       "      <td>{2020: 393548.0, 2021: 273220.0, 2022: 390357....</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  registered_num               name                    website  \\\n",
       "6        1004043  ELMLEY FOUNDATION  https://www.elmley.org.uk   \n",
       "\n",
       "                                          activities  \\\n",
       "6  GRANTMAKING TO THE ARTS IN HEREFORDSHIRE AND W...   \n",
       "\n",
       "                                          objectives  income_latest  \\\n",
       "6  THE ADVANCEMENT OF EDUCATION BY PROMOTING THE ...       503017.0   \n",
       "\n",
       "   expenditure_latest                              objectives_activities  \\\n",
       "6            427809.0  THE MAIN OBJECT OF THE ALLEY FOUNDATION IS THE...   \n",
       "\n",
       "                            achievements_performance  \\\n",
       "6  DURING THE YEAR 55 (2023 - 46) GRANTS WERE PAI...   \n",
       "\n",
       "                                        grant_policy  is_potential_sbf  \\\n",
       "6  THE FOUNDATION RUNS A MAIN GRANTS PROGRAMMED A...             False   \n",
       "\n",
       "   is_on_list  is_nua                                            name_em  \\\n",
       "6       False   False  [-0.013806051,0.004415134,-0.039929647,-0.0218...   \n",
       "\n",
       "                                       activities_em  \\\n",
       "6  [-0.00052015856,0.05774775,-0.019198824,0.0320...   \n",
       "\n",
       "                                       objectives_em  \\\n",
       "6  [0.024830407,0.02097424,-0.024029357,-0.000506...   \n",
       "\n",
       "                            objectives_activities_em  \\\n",
       "6  [-0.010489335,0.04122564,-0.05875264,-0.031378...   \n",
       "\n",
       "                         achievements_performance_em  \\\n",
       "6  [0.0078094695,0.030438136,-0.021327853,-0.0223...   \n",
       "\n",
       "                                     grant_policy_em  \\\n",
       "6  [-0.017348576,0.040816862,-0.036546793,-0.0099...   \n",
       "\n",
       "                                           concat_em  \\\n",
       "6  [0.0057244967,0.0213804,0.00524321,-0.01299309...   \n",
       "\n",
       "                                     extracted_class  \\\n",
       "6  [\"HEREFORD\",\"WORCESTER\",\"WORCESTERSHIRE\",\"ARTS...   \n",
       "\n",
       "                            causes                            areas  \\\n",
       "6  [Arts/culture/heritage/science]  [Herefordshire, Worcestershire]   \n",
       "\n",
       "            beneficiaries                                     income_history  \\\n",
       "6  [Other Defined Groups]  {2020: 420914.0, 2021: 247044.0, 2022: 396098....   \n",
       "\n",
       "                                 expenditure_history list_entries  \n",
       "6  {2020: 393548.0, 2021: 273220.0, 2022: 390357....           []  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get funder data from number inputted by user\n",
    "funder_df = funders_df[funders_df[\"registered_num\"] == funder_num].copy()\n",
    "funder_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grant_title</th>\n",
       "      <th>grant_desc</th>\n",
       "      <th>amount</th>\n",
       "      <th>year</th>\n",
       "      <th>grant_id</th>\n",
       "      <th>source</th>\n",
       "      <th>grant_title_em</th>\n",
       "      <th>grant_desc_em</th>\n",
       "      <th>grant_concat_em</th>\n",
       "      <th>grant_extracted_class</th>\n",
       "      <th>funder_num</th>\n",
       "      <th>funder_grants_id</th>\n",
       "      <th>funder_name</th>\n",
       "      <th>recipient_id</th>\n",
       "      <th>recipient_grants_id</th>\n",
       "      <th>recipient_name</th>\n",
       "      <th>recipient_activities</th>\n",
       "      <th>recipient_objectives</th>\n",
       "      <th>recipient_name_em</th>\n",
       "      <th>recipient_activities_em</th>\n",
       "      <th>recipient_objectives_em</th>\n",
       "      <th>recipient_concat_em</th>\n",
       "      <th>is_recipient</th>\n",
       "      <th>recipient_extracted_class</th>\n",
       "      <th>recipient_areas</th>\n",
       "      <th>recipient_causes</th>\n",
       "      <th>recipient_beneficiaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020_1004043_1</td>\n",
       "      <td>Accounts</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1004043</td>\n",
       "      <td>71219</td>\n",
       "      <td>ELMLEY FOUNDATION</td>\n",
       "      <td>360G-EFF-001b000003VM07f</td>\n",
       "      <td>70020</td>\n",
       "      <td>2FACED DANCE COMPANY</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.027193446,0.029611975,-0.04326912,0.0223630...</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>[-0.019817753,-0.00571729,0.022262126,-0.03666...</td>\n",
       "      <td>True</td>\n",
       "      <td>[\"DANCE\"]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  grant_title grant_desc   amount  year        grant_id    source  \\\n",
       "5        None       None  19000.0  2020  2020_1004043_1  Accounts   \n",
       "\n",
       "                                      grant_title_em  \\\n",
       "5  [-0.019817753,-0.00571729,0.022262126,-0.03666...   \n",
       "\n",
       "                                       grant_desc_em  \\\n",
       "5  [-0.019817753,-0.00571729,0.022262126,-0.03666...   \n",
       "\n",
       "                                     grant_concat_em grant_extracted_class  \\\n",
       "5  [-0.019817753,-0.00571729,0.022262126,-0.03666...                    []   \n",
       "\n",
       "  funder_num  funder_grants_id        funder_name              recipient_id  \\\n",
       "5    1004043             71219  ELMLEY FOUNDATION  360G-EFF-001b000003VM07f   \n",
       "\n",
       "   recipient_grants_id        recipient_name recipient_activities  \\\n",
       "5                70020  2FACED DANCE COMPANY                 None   \n",
       "\n",
       "  recipient_objectives                                  recipient_name_em  \\\n",
       "5                 None  [0.027193446,0.029611975,-0.04326912,0.0223630...   \n",
       "\n",
       "                             recipient_activities_em  \\\n",
       "5  [-0.019817753,-0.00571729,0.022262126,-0.03666...   \n",
       "\n",
       "                             recipient_objectives_em  \\\n",
       "5  [-0.019817753,-0.00571729,0.022262126,-0.03666...   \n",
       "\n",
       "                                 recipient_concat_em  is_recipient  \\\n",
       "5  [-0.019817753,-0.00571729,0.022262126,-0.03666...          True   \n",
       "\n",
       "  recipient_extracted_class recipient_areas recipient_causes  \\\n",
       "5                 [\"DANCE\"]              []               []   \n",
       "\n",
       "  recipient_beneficiaries  \n",
       "5                      []  "
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get grants for selected funder\n",
    "funder_grants_df = grants_df[grants_df[\"funder_num\"] == funder_num].copy()\n",
    "funder_grants_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Criteria (Stated Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Single-Beneficiary Funders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funder has a single beneficiary: False\n"
     ]
    }
   ],
   "source": [
    "#check if funder has a single beneficiary\n",
    "is_sbf = funder_df[\"is_potential_sbf\"].iloc[0]\n",
    "print(f\"Funder has a single beneficiary: {is_sbf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: No Unsolicited Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funder states no unsolicited applications: False\n",
      "NUA score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#check if funder states no unsolicited applications\n",
    "is_nua = funder_df[\"is_nua\"].iloc[0]\n",
    "print(f\"Funder states no unsolicited applications: {is_nua}\")\n",
    "print(f\"NUA score: {is_nua * 1.0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funder is on The List: False\n",
      "Type of List entry: None\n",
      "Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#check if funder is on the list\n",
    "def check_is_on_list(funder_df):\n",
    "\n",
    "    is_on_list = funder_df[\"is_on_list\"].iloc[0]\n",
    "    reasoning = []\n",
    "\n",
    "    if is_on_list:\n",
    "        reasoning = set(funder_df[\"list_entries\"].iloc[0])\n",
    "    else:\n",
    "        reasoning = None\n",
    "    \n",
    "    score = 0.0 if is_on_list else 1.0\n",
    "    \n",
    "    return is_on_list, reasoning, score\n",
    "\n",
    "is_on_list, list_reasoning, list_score = check_is_on_list(funder_df)\n",
    "print(f\"Funder is on The List: {is_on_list}\")\n",
    "print(f\"Type of List entry: {list_reasoning}\")\n",
    "print(f\"Score: {list_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Existing Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funder and user have existing relationship: False\n",
      "Funder has given 0 grant(s) to user\n"
     ]
    }
   ],
   "source": [
    "#check if funder has ever given a grant to applicant\n",
    "existing_relationship = False\n",
    "relationship = grants_df[\n",
    "    (grants_df[\"funder_num\"] == funder_num) &\n",
    "    (grants_df[\"recipient_id\"] == user_num)\n",
    "]\n",
    "num_grants = len(relationship)\n",
    "\n",
    "if num_grants > 0:\n",
    "    existing_relationship = True\n",
    "\n",
    "print(f\"Funder and user have existing relationship: {existing_relationship}\")\n",
    "print(f\"Funder has given {num_grants} grant(s) to user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Criteria (Stated Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring for areas uses hierarchical matching to account for parent-child geographic relationships. The granularity of each area affects its weight - specific locations like local authorities score higher (1.0) than broad regions (0.7). \n",
    "\n",
    "I will check three types of matches:\n",
    "- Exact matches where both funder and user state that they work in the same area\n",
    "- Hierarchical matches where the funder's area contains the user's (e.g., funder says \"Throughout England\", user works in \"Bristol\")\n",
    "- Hierarchical matches where the user's area contains the funder's specific location (e.g., user works throughout \"Africa\", funder focuses on \"Kenya\"). \n",
    "\n",
    "Each match will be weighted differently to reflect the strength of the match. The final score will average only the matched areas, ignoring non-matches, so that having some high-quality geographic alignment is valued over penalising for coverage gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Areas score: 1.00\n",
      "\n",
      "Reasoning:\n",
      "No match: Gloucestershire\n",
      "No match: Shropshire\n",
      "Exact match: Herefordshire\n",
      "Exact match: Worcestershire\n"
     ]
    }
   ],
   "source": [
    "def check_areas(funder_list, user_list, areas_df, hierarchies_df):\n",
    "    \"\"\"\n",
    "    Calculates a score based on matches between the funder's and user's stated areas.\n",
    "    \"\"\"\n",
    "\n",
    "    #convert names to ids\n",
    "    funder_ids = [get_id_from_name(name, areas_df) for name in funder_list if get_id_from_name(name, areas_df) is not None]\n",
    "    user_ids = [get_id_from_name(name, areas_df) for name in user_list if get_id_from_name(name, areas_df) is not None]\n",
    "    \n",
    "    #avoid zero division\n",
    "    if len(user_ids) == 0:\n",
    "        return 0.0, []\n",
    "    \n",
    "    #store ids as set and scores/reasoning as lists\n",
    "    funder_set = set(funder_ids)\n",
    "    scores = []\n",
    "    reasoning = []\n",
    "    \n",
    "    for user_area in user_ids:\n",
    "        user_area_name = get_name_from_id(user_area, areas_df)\n",
    "        \n",
    "        #check for exact match\n",
    "        if user_area in funder_set:\n",
    "            score = get_granularity_weight(user_area, areas_df) * 1.0\n",
    "            scores.append(score)\n",
    "            reasoning.append(f\"Exact match: {user_area_name}\")\n",
    "        \n",
    "        #check if user area is within funder area\n",
    "        else:\n",
    "            hierarchy_user_in_funder = None\n",
    "            for funder_area in funder_ids:\n",
    "                if check_if_parent(funder_area, user_area, hierarchies_df):\n",
    "                    hierarchy_user_in_funder = funder_area\n",
    "                    break\n",
    "            \n",
    "            if hierarchy_user_in_funder:\n",
    "                parent_name = get_name_from_id(hierarchy_user_in_funder, areas_df)\n",
    "                score = get_granularity_weight(hierarchy_user_in_funder, areas_df) * 0.6\n",
    "                scores.append(score)\n",
    "                reasoning.append(f\"Hierarchical match: {user_area_name} (user) within {parent_name} (funder)\")\n",
    "            \n",
    "            #check if funder area is within user area\n",
    "            else:\n",
    "                hierarchy_funder_in_user = None\n",
    "                for funder_area in funder_ids:\n",
    "                    if check_if_parent(user_area, funder_area, hierarchies_df):\n",
    "                        hierarchy_funder_in_user = funder_area\n",
    "                        break\n",
    "                \n",
    "                if hierarchy_funder_in_user:\n",
    "                    child_name = get_name_from_id(hierarchy_funder_in_user, areas_df)\n",
    "                    score = get_granularity_weight(user_area, areas_df) * 0.4\n",
    "                    scores.append(score)\n",
    "                    reasoning.append(f\"Hierarchical match: {child_name} (funder) within {user_area_name} (user)\")\n",
    "                \n",
    "                #no match\n",
    "                else:\n",
    "                    scores.append(0.0)\n",
    "                    reasoning.append(f\"No match: {user_area_name}\")\n",
    "    \n",
    "    matched_scores = [s for s in scores if s > 0]\n",
    "    if len(matched_scores) > 0:\n",
    "        score = sum(matched_scores) / len(matched_scores)\n",
    "    else:\n",
    "        score = 0.0\n",
    "    \n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get lists\n",
    "funder_areas = funder_df[\"areas\"].iloc[0].copy()\n",
    "user_areas = user_df[\"user_areas\"].iloc[0].copy()\n",
    "\n",
    "#get score and reasoning\n",
    "areas_score, areas_reasoning = check_areas(funder_areas, user_areas, areas_df, hierarchies_df)\n",
    "print(f\"Areas score: {areas_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in areas_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring for beneficiaries is simpler than for areas. I will exclude the generic \"Other Charities Or Voluntary Bodies\" as it is likely that almost all funders will fall into this category, adding noise to the scoring. I will use a hierarchical scoring approach but without the granularity weighting, as the higher level categories in this classification are too broad as to offer real value to the calculation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beneficiaries score: 0.20\n",
      "\n",
      "Reasoning:\n",
      "Weak match: user states 'Children/young People' and funder supports broad categories\n",
      "Weak match: user states 'Elderly/old People' and funder supports broad categories\n",
      "Weak match: user states 'People With Disabilities' and funder supports broad categories\n",
      "Weak match: user states 'The General Public/mankind' and funder supports broad categories\n"
     ]
    }
   ],
   "source": [
    "def check_beneficiaries(funder_list, user_list):\n",
    "    \"\"\"\n",
    "    Calculates a score based on matches between the funder's and user's stated beneficiaries.\n",
    "    \"\"\"\n",
    "\n",
    "    #define categories and filter\n",
    "    high_level_bens = {\"Other Defined Groups\", \"The General Public/mankind\"}\n",
    "    exclude_bens = {\"Other Charities Or Voluntary Bodies\"}\n",
    "    funder_bens = [ben for ben in funder_list if ben not in exclude_bens]\n",
    "    user_bens = [ben for ben in user_list if ben not in exclude_bens]\n",
    "    \n",
    "    #avoid zero division\n",
    "    if len(user_bens) == 0:\n",
    "        return 0.0, []\n",
    "    \n",
    "    #categorise funder beneficiaries\n",
    "    funder_specific = set(ben for ben in funder_bens if ben not in high_level_bens)\n",
    "    has_high_level = any(ben in high_level_bens for ben in funder_bens)\n",
    "    \n",
    "    scores = []\n",
    "    reasoning = []\n",
    "    for user_ben in user_bens:\n",
    "        if user_ben in funder_specific:\n",
    "            scores.append(1.0)\n",
    "            reasoning.append(f\"Exact match: {user_ben}\")\n",
    "        elif has_high_level:\n",
    "            scores.append(0.2)\n",
    "            reasoning.append(f\"Weak match: user states '{user_ben}' and funder supports broad categories\")\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "            reasoning.append(f\"No match: {user_ben}\")\n",
    "    \n",
    "    matched_scores = [s for s in scores if s > 0]\n",
    "    if len(matched_scores) > 0:\n",
    "        score = sum(matched_scores) / len(matched_scores)\n",
    "    else:\n",
    "        score = 0.0\n",
    "\n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get lists\n",
    "funder_beneficiaries = funder_df[\"beneficiaries\"].iloc[0].copy()\n",
    "user_beneficiaries = user_df[\"user_beneficiaries\"].iloc[0].copy()\n",
    "\n",
    "#get score and reasoning\n",
    "beneficiaries_score, beneficiaries_reasoning = check_beneficiaries(funder_beneficiaries, user_beneficiaries)\n",
    "print(f\"Beneficiaries score: {beneficiaries_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in beneficiaries_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For causes, I will exclude \"Other Charitable Purposes\" as it adds noise. However, I will not exclude \"General Charitable Purposes\" (GCP) as this is used by funders to indicate that they would be willing to consider any causes. I will use it as a fallback similar to how \"Throughout England\" works for areas. \n",
    "\n",
    "The scoring checks for exact matches between the user's and funder's causes first, which score 1.0. If no exact match exists but the funder lists GCP, this scores 0.5 as a weak indicator that the funder might support the cause. Non-matches score 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causes score: 1.00\n",
      "\n",
      "Reasoning:\n",
      "No match: Education/training\n",
      "Exact match: Arts/culture/heritage/science\n"
     ]
    }
   ],
   "source": [
    "def check_causes(funder_list, user_list):\n",
    "    \"\"\"\n",
    "    Calculates a score based on matches between the funder's and user's stated causes.\n",
    "    \"\"\"\n",
    "    #define categories and filter\n",
    "    gcp = \"General Charitable Purposes\"\n",
    "    exclude_causes = {\"Other Charitable Purposes\"}\n",
    "    funder_causes = [cause for cause in funder_list if cause not in exclude_causes]\n",
    "    user_causes = [cause for cause in user_list if cause not in exclude_causes]\n",
    "    \n",
    "    #avoid zero division\n",
    "    if len(user_causes) == 0:\n",
    "        return 0.0, []\n",
    "    \n",
    "    #categorise funder causes\n",
    "    funder_specific = set(cause for cause in funder_causes if cause != gcp)\n",
    "    has_gcp = gcp in funder_causes\n",
    "    \n",
    "    scores = []\n",
    "    reasoning = []\n",
    "    \n",
    "    for user_cause in user_causes:\n",
    "        if user_cause in funder_specific:\n",
    "            scores.append(1.0)\n",
    "            reasoning.append(f\"Exact match: {user_cause}\")\n",
    "        elif has_gcp:\n",
    "            scores.append(0.6)\n",
    "            reasoning.append(f\"Weak match: user states '{user_cause}' and funder supports general charitable purposes\")\n",
    "        else:\n",
    "            scores.append(0.0)\n",
    "            reasoning.append(f\"No match: {user_cause}\")\n",
    "    \n",
    "    matched_scores = [s for s in scores if s > 0]\n",
    "    if len(matched_scores) > 0:\n",
    "        score = sum(matched_scores) / len(matched_scores)\n",
    "    else:\n",
    "        score = 0.0\n",
    "    \n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get lists\n",
    "funder_causes = funder_df[\"causes\"].iloc[0].copy()\n",
    "user_causes = user_df[\"user_causes\"].iloc[0].copy()\n",
    "\n",
    "#get score and reasoning\n",
    "causes_score, causes_reasoning = check_causes(funder_causes, user_causes)\n",
    "print(f\"Causes score: {causes_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in causes_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity (Stated Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Text Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text semantic similarity score: 0.20\n"
     ]
    }
   ],
   "source": [
    "#get embeddings\n",
    "funder_embedding = funder_df[\"concat_em\"].iloc[0]\n",
    "user_embedding = user_df[\"concat_em\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "text_similarity_score = calculate_similarity_score(funder_embedding, user_embedding)\n",
    "print(f\"Text semantic similarity score: {text_similarity_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword similarity score: 0.48\n",
      "Eligible for keyword bonus: True\n"
     ]
    }
   ],
   "source": [
    "def check_keywords(funder_keywords, user_keywords, model):\n",
    "    \"\"\"\n",
    "    Calculates semantic similarity between funder (extracted) and user (inputted) keywords.\n",
    "    \"\"\"\n",
    "    \n",
    "    #parse json\n",
    "    if isinstance(funder_keywords, str):\n",
    "        funder_keywords = json.loads(funder_keywords)\n",
    "    if isinstance(user_keywords, str):\n",
    "        user_keywords = json.loads(user_keywords)\n",
    "    \n",
    "    #handle empty/nans\n",
    "    if not funder_keywords:\n",
    "        funder_keywords = []\n",
    "    if not user_keywords:\n",
    "        user_keywords = []\n",
    "    \n",
    "    if len(funder_keywords) == 0 or len(user_keywords) == 0:\n",
    "        return 0.0, {}, [\"No keywords to compare\"],\n",
    "    \n",
    "    #create embeddings for each keyword\n",
    "    funder_keywords_em = {}\n",
    "    for keyword in funder_keywords:\n",
    "        embedding = model.encode(keyword)\n",
    "        funder_keywords_em[keyword] = embedding\n",
    "\n",
    "    user_keywords_em = {}\n",
    "    for keyword in user_keywords:\n",
    "        embedding = model.encode(keyword)\n",
    "        user_keywords_em[keyword] = embedding\n",
    "\n",
    "    #compare every funder keyword to every user keyword\n",
    "    all_scores = []\n",
    "    for funder_kw, funder_em in funder_keywords_em.items():\n",
    "        for user_kw, user_em in user_keywords_em.items():\n",
    "            similarity = calculate_similarity_score(funder_em, user_em)\n",
    "            all_scores.append({\n",
    "                \"funder_keyword\": funder_kw,\n",
    "                \"user_keyword\": user_kw,\n",
    "                \"similarity\": similarity\n",
    "            })\n",
    "    \n",
    "    #sort and check for bonus (matches >= 0.8)\n",
    "    all_scores.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    gets_bonus = any(match[\"similarity\"] >= 0.80 for match in all_scores)\n",
    "    \n",
    "    #get dictionary of matches >= 0.80\n",
    "    strong_matches = {}\n",
    "    for match in all_scores:\n",
    "        if match[\"similarity\"] >= 0.80:\n",
    "            key = f\"{match['funder_keyword']} & {match['user_keyword']}\"\n",
    "            strong_matches[key] = match[\"similarity\"]\n",
    "    \n",
    "    #filter to top 10 matches <= 0.80 and get average\n",
    "    scores_under_80 = [match for match in all_scores if match[\"similarity\"] < 0.80]\n",
    "    top_10 = scores_under_80[:10]\n",
    "\n",
    "    if len(top_10) > 0:\n",
    "        score = sum(match[\"similarity\"] for match in top_10) / len(top_10)\n",
    "    else:\n",
    "        score = 0.0\n",
    "    \n",
    "    #build reasoning from medium matches\n",
    "    reasoning = []\n",
    "    for match in scores_under_80[:9]:\n",
    "        reasoning.append(f\"'{match['funder_keyword']}' & '{match['user_keyword']}': {match['similarity']:.3f}\")\n",
    "    \n",
    "    return max(0.0, score), strong_matches, reasoning, gets_bonus\n",
    "\n",
    "#get keyword lists\n",
    "funder_keywords = funder_df[\"extracted_class\"].iloc[0]\n",
    "user_keywords = user_df[\"user_extracted_class\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "keyword_similarity_score, keyword_strong_matches, keyword_reasoning, keyword_gets_bonus = check_keywords(funder_keywords, user_keywords, model)\n",
    "\n",
    "print(f\"Keyword similarity score: {keyword_similarity_score:.2f}\")\n",
    "print(f\"Eligible for keyword bonus: {keyword_gets_bonus}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Similarity (Revealed Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Name Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name (RP) similarity score: 0.50\n",
      "\n",
      "Reasoning:\n",
      "REBURY POETRY FESTIVAL: 0.683\n",
      "BROMSGROVE CONCERTS: 0.490\n",
      "HEREFORD CATHEDRAL: 0.487\n",
      "WORCESTER CATHEDRAL: 0.486\n",
      "LONGBOROUGH FESTIVAL OPERA: 0.481\n",
      "COURTYARD CENTER FOR THE ARTS: 0.480\n",
      "MEADOW ARTS: 0.478\n",
      "MALVERN THEATRE: 0.473\n",
      "JAZZ IN MALVERN: 0.452\n",
      "MEADOWLARKS: 0.446\n"
     ]
    }
   ],
   "source": [
    "def check_name_rp(recipients_embedding_dict, user_embedding, user_name):\n",
    "    \"\"\"\n",
    "    Calculates semantic similarity between the user's name and the names of the funder's previous recipients.\n",
    "    \"\"\"\n",
    "\n",
    "    #handle empty/nan\n",
    "    score = 0.0\n",
    "    reasoning = []\n",
    "\n",
    "    #compare every recipient name to the user's name\n",
    "    all_scores = []\n",
    "    for recipient_name, recipient_embedding in recipients_embedding_dict.items():\n",
    "        if recipient_name != user_name:\n",
    "            similarity = calculate_similarity_score(recipient_embedding, user_embedding)\n",
    "            all_scores.append({\n",
    "                \"recipient_name\": recipient_name,\n",
    "                \"similarity\": similarity\n",
    "            })\n",
    "\n",
    "    #sort and calculate average of top 10\n",
    "    all_scores.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    top_10 = all_scores[:10]\n",
    "    if len(top_10) > 0:\n",
    "        score = sum(match[\"similarity\"] for match in top_10) / len(top_10)\n",
    "    else:\n",
    "        score = 0.0\n",
    "\n",
    "    #build reasoning from top 10 matches\n",
    "    reasoning = []\n",
    "    for match in top_10:\n",
    "        reasoning.append(f\"{match['recipient_name']}: {match['similarity']:.3f}\")\n",
    "\n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get embeddings\n",
    "recipients_name_all_em = dict(zip(funder_grants_df[\"recipient_name\"], funder_grants_df[\"recipient_name_em\"]))\n",
    "user_name_em = user_df[\"user_name_em\"].iloc[0]\n",
    "user_name = user_df[\"user_name\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "name_score_rp, name_rp_reasoning = check_name_rp(recipients_name_all_em, user_name_em, user_name)\n",
    "print(f\"Name (RP) similarity score: {name_score_rp:.2f}\\n\\nReasoning:\")\n",
    "for reason in name_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Grants Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grants (RP) similarity score: 0.00\n",
      "\n",
      "Reasoning:\n"
     ]
    }
   ],
   "source": [
    "def check_grants_rp(grants_embedding_dict, user_embedding, user_name):\n",
    "    \"\"\"\n",
    "    Calculates semantic similarity between the user's text sections and the funder's previous grants.\n",
    "    \"\"\"\n",
    "\n",
    "    #handle empty/nan\n",
    "    score = 0.0\n",
    "    reasoning = []\n",
    "\n",
    "    #compare every grant to the user's text\n",
    "    all_scores = []\n",
    "    for grant_recipient_name, grant_embedding in grants_embedding_dict.items():\n",
    "        if grant_recipient_name != user_name:\n",
    "            similarity = calculate_similarity_score(grant_embedding, user_embedding)\n",
    "            all_scores.append({\n",
    "                \"grant_recipient_name\": grant_recipient_name,\n",
    "                \"similarity\": similarity\n",
    "            })\n",
    "\n",
    "    #sort and calculate average of top 10\n",
    "    all_scores.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    top_10 = all_scores[:10]\n",
    "    if len(top_10) > 0:\n",
    "        score = sum(match[\"similarity\"] for match in top_10) / len(top_10)\n",
    "    else:\n",
    "        score = 0.0\n",
    "\n",
    "    #build reasoning from top 10 matches\n",
    "    reasoning = []\n",
    "    for match in top_10:\n",
    "        reasoning.append(f\"{match['grant_recipient_name']}: {match['similarity']:.3f}\")\n",
    "\n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get embeddings\n",
    "non_empty_grants = funder_grants_df[\n",
    "    (funder_grants_df[\"grant_title\"].notna() & (funder_grants_df[\"grant_title\"] != \"\")) |\n",
    "    (funder_grants_df[\"grant_desc\"].notna() & (funder_grants_df[\"grant_desc\"] != \"\"))\n",
    "]\n",
    "\n",
    "grants_all_em = dict(zip(non_empty_grants[\"recipient_name\"], non_empty_grants[\"grant_concat_em\"]))\n",
    "user_concat_em = user_df[\"concat_em\"].iloc[0]\n",
    "user_name = user_df[\"user_name\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "grants_rp_score, grants_rp_reasoning = check_grants_rp(grants_all_em, user_concat_em, user_name)\n",
    "print(f\"Grants (RP) similarity score: {grants_rp_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in grants_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Recipients Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipients (RP) similarity score: 0.35\n",
      "\n",
      "Reasoning:\n",
      "MEADOW ARTS: 0.417\n",
      "WORCESTER CONCERT CLUB: 0.391\n",
      "BROMSGROVE CONCERTS: 0.375\n",
      "RURAL MEDIA CHARITY: 0.366\n",
      "EVESHAM ABBEY TRUST: 0.364\n",
      "DANCEFEST: 0.362\n",
      "SOUND AFFAIRS: 0.330\n",
      "LONGBOROUGH FESTIVAL OPERA: 0.317\n",
      "HAY MUSIC TRUST: 0.312\n",
      "MIDLAND SINFONIA: 0.310\n"
     ]
    }
   ],
   "source": [
    "def check_recipients_rp(recipients_embedding_dict, user_embedding, user_name):\n",
    "    \"\"\"\n",
    "    Calculates semantic similarity between the user's text sections and those of the funder's previous recipients.\n",
    "    \"\"\"\n",
    "\n",
    "    #handle empty/nan\n",
    "    score = 0.0\n",
    "    reasoning = []\n",
    "\n",
    "    #compare every recipient's text to the user's text\n",
    "    all_scores = []\n",
    "    for recipient_name, recipient_embedding in recipients_embedding_dict.items():\n",
    "        if recipient_name != user_name:\n",
    "            similarity = calculate_similarity_score(recipient_embedding, user_embedding)\n",
    "            all_scores.append({\n",
    "                \"grant_recipient_name\": recipient_name,\n",
    "                \"similarity\": similarity\n",
    "            })\n",
    "\n",
    "    #sort and calculate average of top 10\n",
    "    all_scores.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "    top_10 = all_scores[:10]\n",
    "    if len(top_10) > 0:\n",
    "        score = sum(match[\"similarity\"] for match in top_10) / len(top_10)\n",
    "    else:\n",
    "        score = 0.0\n",
    "\n",
    "    #build reasoning from top 10 matches\n",
    "    reasoning = []\n",
    "    for match in top_10:\n",
    "        reasoning.append(f\"{match['grant_recipient_name']}: {match['similarity']:.3f}\")\n",
    "\n",
    "    return max(0.0, score), reasoning\n",
    "\n",
    "#get embeddings\n",
    "recipients_all_em = dict(zip(funder_grants_df[\"recipient_name\"], funder_grants_df[\"recipient_concat_em\"]))\n",
    "user_concat_em = user_df[\"concat_em\"].iloc[0]\n",
    "user_name = user_df[\"user_name\"].iloc[0]\n",
    "\n",
    "#get score\n",
    "recipients_rp_score, recipients_rp_reasoning = check_recipients_rp(recipients_all_em, user_concat_em, user_name)\n",
    "print(f\"Recipients (RP) similarity score: {recipients_rp_score:.2f}\\n\\nReasoning:\")\n",
    "for reason in recipients_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalties and Bonuses (Stated Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: SBF Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-beneficiary penalty: *1.0\n"
     ]
    }
   ],
   "source": [
    "sbf_penalty = 0.2 if is_sbf else 1.0\n",
    "print(f\"Single-beneficiary penalty: *{sbf_penalty}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Keywords Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 strong keyword matches:\n",
      "ARTS: 1.00\n",
      "POLICY CAMPAIGNING AND ADVOCACY: 1.00\n",
      "EDUCATION: 1.00\n",
      "Keywords bonus: *1.10\n"
     ]
    }
   ],
   "source": [
    "def calculate_keywords_bonus(strong_matches):\n",
    "    \"\"\"\n",
    "    Calculates bonus based on keyword matches. Only runs if keywords with semantic scores above 0.8 exist.\n",
    "    \"\"\"\n",
    "\n",
    "    #get average of scores >= 0.8\n",
    "    avg_score = sum(strong_matches.values()) / len(strong_matches)\n",
    "    \n",
    "    #convert to bonus multiplier\n",
    "    bonus = 1.0 + (avg_score - 0.8) * 0.5\n",
    "    \n",
    "    return bonus\n",
    "\n",
    "#get bonus and reasoning\n",
    "keywords_bonus = calculate_keywords_bonus(keyword_strong_matches)\n",
    "\n",
    "print(f\"{len(keyword_strong_matches)} strong keyword matches:\")\n",
    "for match, score in keyword_strong_matches.items():\n",
    "    first_keyword = match.split(\" & \")[0]\n",
    "    print(f\"{first_keyword}: {score:.2f}\")\n",
    "print(f\"Keywords bonus: *{keywords_bonus:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Existing Relationship Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last gift given in nan (nan years ago)\n",
      "Relationship bonus: *1.1\n"
     ]
    }
   ],
   "source": [
    "def calculate_relationship_bonus(relationship_df):\n",
    "    \"\"\"\n",
    "    Calculates time since last grant and calculates a bonus. Only runs if there is a relationship.\n",
    "    \"\"\"\n",
    "\n",
    "    #get time lapsed since last gift\n",
    "    last_grant_year = relationship_df[\"year\"].max()\n",
    "    current_year = datetime.now().year\n",
    "    time_lapsed = current_year - last_grant_year\n",
    "    \n",
    "    #assign bands\n",
    "    if time_lapsed <= 2:\n",
    "        bonus = 1.5\n",
    "    elif time_lapsed <= 3:\n",
    "        bonus = 1.4\n",
    "    elif time_lapsed <= 5:\n",
    "        bonus = 1.3\n",
    "    elif time_lapsed <= 10:\n",
    "        bonus = 1.2\n",
    "    else:\n",
    "        bonus = 1.1\n",
    "    \n",
    "    #add uplift for recurring relationship\n",
    "    num_grants = len(relationship_df)\n",
    "    if num_grants >= 5:\n",
    "        bonus += 0.1\n",
    "    \n",
    "    return time_lapsed, bonus, last_grant_year\n",
    "\n",
    "#get bonus and reasoning\n",
    "time_lapsed, relationship_bonus, last_grant_year = calculate_relationship_bonus(relationship)\n",
    "\n",
    "print(f\"Last gift given in {last_grant_year} ({time_lapsed} years ago)\")\n",
    "print(f\"Relationship bonus: *{relationship_bonus}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalties and Bonuses (Revealed Preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: Areas Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Areas score: 1.11\n",
      "\n",
      "Reasoning:\n",
      "Gloucestershire: 5 grants (100.0%)\n"
     ]
    }
   ],
   "source": [
    "def calculate_areas_bonus_rp(funder_grants_df, user_areas, areas_df, hierarchies_df):\n",
    "    \"\"\"\n",
    "    Calculates a bonus based on how well the user's areas match the funder's recipient's areas.\n",
    "    \"\"\"\n",
    "\n",
    "    if funder_grants_df.empty:\n",
    "        return 0.0, [\"No grants history available\"]\n",
    "\n",
    "    #get unique areas from recipients\n",
    "    all_areas = []\n",
    "    for areas_list in funder_grants_df[\"recipient_areas\"]:\n",
    "        if isinstance(areas_list, list):\n",
    "            all_areas.extend(areas_list)\n",
    "\n",
    "    if len(all_areas) == 0:\n",
    "        return 0.0, [\"No area data available\"]\n",
    "\n",
    "    recipient_areas = list(set(all_areas))\n",
    "\n",
    "    #check areas\n",
    "    match_score, _ = check_areas(recipient_areas, user_areas, areas_df, hierarchies_df)\n",
    "\n",
    "    #convert to bonus multiplier\n",
    "    bonus = 1.0 + (match_score * 0.2)\n",
    "\n",
    "    #get reasoning from top 10 (low level tiers only)\n",
    "    area_count = {}\n",
    "    for area_name in all_areas:\n",
    "        area_id = get_id_from_name(area_name, areas_df)\n",
    "        if area_id:\n",
    "            granularity = get_granularity_weight(area_id, areas_df)\n",
    "            if granularity >= 0.9:\n",
    "                area_count[area_name] = area_count.get(area_name, 0) + 1\n",
    "\n",
    "    if len(area_count) == 0:\n",
    "        reasoning = [\"Only broad geographic areas found\"]\n",
    "    else:\n",
    "        sorted_areas = sorted(area_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        total_low_level = sum(area_count.values())\n",
    "\n",
    "        reasoning = []\n",
    "        for area_name, count in sorted_areas[:10]:\n",
    "            percentage = (count / total_low_level) * 100\n",
    "            reasoning.append(f\"{area_name}: {count} grants ({percentage:.1f}%)\")\n",
    "\n",
    "    return bonus, reasoning\n",
    "\n",
    "#get list\n",
    "user_areas = user_df[\"user_areas\"].iloc[0].copy()\n",
    "\n",
    "#get bonus and reasoning\n",
    "areas_rp_bonus, areas_rp_reasoning = calculate_areas_bonus_rp(funder_grants_df, user_areas, areas_df, hierarchies_df)\n",
    "print(f\"Areas score: {areas_rp_bonus:.2f}\\n\\nReasoning:\")\n",
    "for reason in areas_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 17: Keywords Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords (RP) bonus: *1.05\n",
      "\n",
      "Reasoning:\n",
      "ARTS: 43 occurrences\n",
      "FESTIVAL: 35 occurrences\n",
      "EDUCATION: 25 occurrences\n",
      "POLICY CAMPAIGNING AND ADVOCACY: 15 occurrences\n",
      "CHILDREN: 3 occurrences\n"
     ]
    }
   ],
   "source": [
    "def calculate_keywords_bonus_rp(funder_grants_df, user_keywords):\n",
    "    \"\"\"\n",
    "    Calculates a bonus based on exact keyword matches between user and funder's recipients.\n",
    "    \"\"\"\n",
    "\n",
    "    if funder_grants_df.empty:\n",
    "        return 1.0, [\"No grants history available\"]\n",
    "\n",
    "    #parse json\n",
    "    if isinstance(user_keywords, str):\n",
    "        user_keywords = json.loads(user_keywords)\n",
    "    if not user_keywords:\n",
    "        user_keywords = []\n",
    "\n",
    "    if len(user_keywords) == 0:\n",
    "        return 1.0, [\"No user keywords to match\"]\n",
    "\n",
    "    #get all recipient keywords\n",
    "    all_recipient_keywords = []\n",
    "    for recipient_keywords in funder_grants_df[\"recipient_extracted_class\"]:\n",
    "        if isinstance(recipient_keywords, str):\n",
    "            recipient_keywords = json.loads(recipient_keywords)\n",
    "        if recipient_keywords:\n",
    "            all_recipient_keywords.extend(recipient_keywords)\n",
    "\n",
    "    if len(all_recipient_keywords) == 0:\n",
    "        return 1.0, [\"No recipient keywords available\"]\n",
    "\n",
    "    #find exact matches and count frequency\n",
    "    matched_keywords = {}\n",
    "    user_keywords_matched = set()\n",
    "\n",
    "    for user_kw in user_keywords:\n",
    "        if user_kw in all_recipient_keywords:\n",
    "            user_keywords_matched.add(user_kw)\n",
    "            matched_keywords[user_kw] = matched_keywords.get(user_kw, 0) + all_recipient_keywords.count(user_kw)\n",
    "\n",
    "    #calculate match percentage\n",
    "    match_percentage = len(user_keywords_matched) / len(user_keywords)\n",
    "\n",
    "    #calculate bonus\n",
    "    if match_percentage >= 0.9:\n",
    "        bonus = 1.1\n",
    "    elif match_percentage >= 0.5:\n",
    "        bonus = 1.05\n",
    "    else:\n",
    "        bonus = 1.0 + (match_percentage * 0.2)\n",
    "\n",
    "    #build reasoning from top 10\n",
    "    if len(matched_keywords) == 0:\n",
    "        reasoning = [\"No exact keyword matches found\"]\n",
    "    else:\n",
    "        sorted_matches = sorted(matched_keywords.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        reasoning = []\n",
    "        for keyword, count in sorted_matches[:10]:\n",
    "            reasoning.append(f\"{keyword}: {count} occurrences\")\n",
    "\n",
    "    return bonus, reasoning\n",
    "\n",
    "#get list\n",
    "user_keywords = user_df[\"user_extracted_class\"].iloc[0]\n",
    "\n",
    "#get bonus and reasoning\n",
    "keywords_rp_bonus, keywords_rp_reasoning = calculate_keywords_bonus_rp(funder_grants_df, user_keywords)\n",
    "print(f\"Keywords (RP) bonus: *{keywords_rp_bonus:.2f}\\n\\nReasoning:\")\n",
    "for reason in keywords_rp_reasoning:\n",
    "    print(reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prospie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
